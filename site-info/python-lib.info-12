This is python-lib.info, produced by makeinfo version 4.3 from
python-lib.texi.

October 3, 2003


File: python-lib.info,  Node: How are Docstring Examples Recognized?,  Next: Warnings,  Prev: Advanced Usage,  Up: doctest

How are Docstring Examples Recognized?
--------------------------------------

In most cases a copy-and-paste of an interactive console session works
fine--just make sure the leading whitespace is rigidly consistent (you
can mix tabs and spaces if you're too lazy to do it right, but
`doctest' is not in the business of guessing what you think a tab
means).

     >>> # comments are ignored
     >>> x = 12
     >>> x
     12
     >>> if x == 13:
     ...     print "yes"
     ... else:
     ...     print "no"
     ...     print "NO"
     ...     print "NO!!!"
     ...
     no
     NO
     NO!!!
     >>>

Any expected output must immediately follow the final `'>`>'>~'' or
`'...~'' line containing the code, and the expected output (if any)
extends to the next `'>`>'>~'' or all-whitespace line.

The fine print:

   * Expected output cannot contain an all-whitespace line, since such a
     line is taken to signal the end of expected output.

   * Output to stdout is captured, but not output to stderr (exception
     tracebacks are captured via a different means).

   * If you continue a line via backslashing in an interactive session,
     or for any other reason use a backslash, you need to double the
     backslash in the docstring version.  This is simply because you're
     in a string, and so the backslash must be escaped for it to
     survive intact.  Like:

          >>> if "yes" == \\
          ...     "y" +   \\
          ...     "es":
          ...     print 'yes'
          yes

   * The starting column doesn't matter:

            >>> assert "Easy!"
                  >>> import math
                      >>> math.floor(1.9)
                      1.0

     and as many leading whitespace characters are stripped from the
     expected output as appeared in the initial `'>`>'>~'' line that
     triggered it.


File: python-lib.info,  Node: Warnings,  Next: Soapbox,  Prev: How are Docstring Examples Recognized?,  Up: doctest

Warnings
--------

  1. `doctest' is serious about requiring exact matches in expected
     output.  If even a single character doesn't match, the test fails.
     This will probably surprise you a few times, as you learn exactly
     what Python does and doesn't guarantee about output.  For example,
     when printing a dict, Python doesn't guarantee that the key-value
     pairs will be printed in any particular order, so a test like

          >>> foo()
          {"Hermione": "hippogryph", "Harry": "broomstick"}
          >>>

     is vulnerable!  One workaround is to do

          >>> foo() == {"Hermione": "hippogryph", "Harry": "broomstick"}
          1
          >>>

     instead.  Another is to do

          >>> d = foo().items()
          >>> d.sort()
          >>> d
          [('Harry', 'broomstick'), ('Hermione', 'hippogryph')]

     There are others, but you get the idea.

     Another bad idea is to print things that embed an object address,
     like

          >>> id(1.0) # certain to fail some of the time
          7948648
          >>>

     Floating-point numbers are also subject to small output variations
     across platforms, because Python defers to the platform C library
     for float formatting, and C libraries vary widely in quality here.

          >>> 1./7  # risky
          0.14285714285714285
          >>> print 1./7 # safer
          0.142857142857
          >>> print round(1./7, 6) # much safer
          0.142857

     Numbers of the form `I/2.**J' are safe across all platforms, and I
     often contrive doctest examples to produce numbers of that form:

          >>> 3./4  # utterly safe
          0.75

     Simple fractions are also easier for people to understand, and
     that makes for better documentation.

  2. Be careful if you have code that must only execute once.

     If you have module-level code that must only execute once, a more
     foolproof definition of `_test()' is

          def _test():
              import doctest, sys
              doctest.testmod()

  3. WYSIWYG isn't always the case, starting in Python 2.3.  The string
     form of boolean results changed from `'0'' and `'1'' to `'False''
     and `'True'' in Python 2.3.  This makes it clumsy to write a
     doctest showing boolean results that passes under multiple
     versions of Python.  In Python 2.3, by default, and as a special
     case, if an expected output block consists solely of `'0'' and the
     actual output block consists solely of `'False'', that's accepted
     as an exact match, and similarly for `'1'' versus `'True''.  This
     behavior can be turned off by passing the new (in 2.3) module
     constant `DONT_ACCEPT_TRUE_FOR_1' as the value of `testmod()''s
     new (in 2.3) optional OPTIONFLAGS argument.  Some years after the
     integer spellings of booleans are history, this hack will probably
     be removed again.



File: python-lib.info,  Node: Soapbox,  Prev: Warnings,  Up: doctest

Soapbox
-------

The first word in "doctest" is "doc," and that's why the author wrote
`doctest': to keep documentation up to date.  It so happens that
`doctest' makes a pleasant unit testing environment, but that's not its
primary purpose.

Choose docstring examples with care.  There's an art to this that needs
to be learned--it may not be natural at first.  Examples should add
genuine value to the documentation.  A good example can often be worth
many words.  If possible, show just a few normal cases, show endcases,
show interesting subtle cases, and show an example of each kind of
exception that can be raised.  You're probably testing for endcases and
subtle cases anyway in an interactive shell: `doctest' wants to make it
as easy as possible to capture those sessions, and will verify they
continue to work as designed forever after.

If done with care, the examples will be invaluable for your users, and
will pay back the time it takes to collect them many times over as the
years go by and things change.  I'm still amazed at how often one of my
`doctest' examples stops working after a "harmless" change.

For exhaustive testing, or testing boring cases that add no value to the
docs, define a `__test__' dict instead.  That's what it's for.


File: python-lib.info,  Node: unittest,  Next: test,  Prev: doctest,  Up: Miscellaneous Services

Unit testing framework
======================

Unit testing framework for Python.

_Added in Python version 2.1_

The Python unit testing framework, often referred to as "PyUnit," is a
Python language version of JUnit, by Kent Beck and Erich Gamma.  JUnit
is, in turn, a Java version of Kent's Smalltalk testing framework.
Each is the de facto standard unit testing framework for its respective
language.

PyUnit supports test automation, sharing of setup and shutdown code for
tests, aggregation of tests into collections, and independence of the
tests from the reporting framework.  The `unittest' module provides
classes that make it easy to support these qualities for a set of tests.

To achieve this, PyUnit supports some important concepts:

"test fixture"
     A "test fixture" represents the preparation needed to perform one
     or more tests, and any associate cleanup actions.  This may
     involve, for example, creating temporary or proxy databases,
     directories, or starting a server process.

"test case"
     A "test case" is the smallest unit of testing.  It checks for a
     specific response to a particular set of inputs.  PyUnit provides a
     base class, `TestCase', which may be used to create new test cases.

"test suite"
     A "test suite" is a collection of test cases, test suites, or
     both.  It is used to aggregate tests that should be executed
     together.

"test runner"
     A "test runner" is a component which orchestrates the execution of
     tests and provides the outcome to the user.  The runner may use a
     graphical interface, a textual interface, or return a special
     value to indicate the results of executing the tests.

The test case and test fixture concepts are supported through the
`TestCase' and `FunctionTestCase' classes; the former should be used
when creating new tests, and the latter can be used when integrating
existing test code with a PyUnit-driven framework.  When building test
fixtures using `TestCase', the `setUp()' and `tearDown()' methods can
be overridden to provide initialization and cleanup for the fixture.
With `FunctionTestCase', existing functions can be passed to the
constructor for these purposes.  When the test is run, the fixture
initialization is run first; if it succeeds, the cleanup method is run
after the test has been executed, regardless of the outcome of the
test.  Each instance of the `TestCase' will only be used to run a
single test method, so a new fixture is created for each test.

Test suites are implemented by the `TestSuite' class.  This class
allows individual tests and test suites to be aggregated; when the
suite is executed, all tests added directly to the suite and in "child"
test suites are run.

A test runner is an object that provides a single method, `run()',
which accepts a `TestCase' or `TestSuite' object as a parameter, and
returns a result object.  The class `TestResult' is provided for use as
the result object.  PyUnit provide the `TextTestRunner' as an example
test runner which reports test results on the standard error stream by
default.  Alternate runners can be implemented for other environments
(such as graphical environments) without any need to derive from a
specific class.

See also:
     `PyUnit Web Site'{The source for further information on PyUnit.}
     `Simple Smalltalk Testing: With Patterns'{Kent Beck's original
     paper on testing frameworks using the pattern shared by
     `unittest'.}

* Menu:

* Basic example::
* Organizing test code::
* Re-using old test code::
* Classes and functions 2::
* TestCase Objects::
* TestSuite Objects::
* TestResult Objects::
* TestLoader Objects::
* Getting Extended Error Information::


File: python-lib.info,  Node: Basic example,  Next: Organizing test code,  Prev: unittest,  Up: unittest

Basic example
-------------

The `unittest' module provides a rich set of tools for constructing and
running tests.  This section demonstrates that a small subset of the
tools suffice to meet the needs of most users.

Here is a short script to test three functions from the `random' module:

     import random
     import unittest
     
     class TestSequenceFunctions(unittest.TestCase):
     
         def setUp(self):
             self.seq = range(10)
     
         def testshuffle(self):
             # make sure the shuffled sequence does not lose any elements
             random.shuffle(self.seq)
             self.seq.sort()
             self.assertEqual(self.seq, range(10))
     
         def testchoice(self):
             element = random.choice(self.seq)
             self.assert_(element in self.seq)
     
         def testsample(self):
             self.assertRaises(ValueError, random.sample, self.seq, 20)
             for element in random.sample(self.seq, 5):
                 self.assert_(element in self.seq)
     
     if __name__ == '__main__':
         unittest.main()

A testcase is created by subclassing `unittest.TestCase'.  The three
individual tests are defined with methods whose names start with the
letters `test'.  This naming convention informs the test runner about
which methods represent tests.

The crux of each test is a call to `assertEqual()' to check for an
expected result; `assert_()' to verify a condition; or `assertRaises()'
to verify that an expected exception gets raised.  These methods are
used instead of the `assert' statement so the test runner can
accumulate all test results and produce a report.

When a `setUp()' method is defined, the test runner will run that
method prior to each test.  Likewise, if a `tearDown()' method is
defined, the test runner will invoke that method after each test.  In
the example, `setUp()' was used to create a fresh sequence for each
test.

The final block shows a simple way to run the tests.  `unittest.main()'
provides a command line interface to the test script.  When run from the
command line, the above script produces an output that looks like this:

     ...
     ----------------------------------------------------------------------
     Ran 3 tests in 0.000s
     
     OK

Instead of `unittest.main()', there are other ways to run the tests
with a finer level of control, less terse output, and no requirement to
be run from the command line.  For example, the last two lines may be
replaced with:

     suite = unittest.TestSuite()
     suite.addTest(unittest.makeSuite(TestSequenceFunctions))
     unittest.TextTestRunner(verbosity=2).run(suite)

Running the revised script from the interpreter or another script
produces the following output:

     testchoice (__main__.TestSequenceFunctions) ... ok
     testsample (__main__.TestSequenceFunctions) ... ok
     testshuffle (__main__.TestSequenceFunctions) ... ok
     
     ----------------------------------------------------------------------
     Ran 3 tests in 0.110s
     
     OK

The above examples show the most commonly used `unittest' features
which are sufficient to meet many everyday testing needs.  The remainder
of the documentation explores the full feature set from first
principles.


File: python-lib.info,  Node: Organizing test code,  Next: Re-using old test code,  Prev: Basic example,  Up: unittest

Organizing test code
--------------------

The basic building blocks of unit testing are "test cases" -- single
scenarios that must be set up and checked for correctness.  In PyUnit,
test cases are represented by instances of the `TestCase' class in the
`unittest' module. To make your own test cases you must write
subclasses of `TestCase', or use `FunctionTestCase'.

An instance of a `TestCase'-derived class is an object that can
completely run a single test method, together with optional set-up and
tidy-up code.

The testing code of a `TestCase' instance should be entirely self
contained, such that it can be run either in isolation or in arbitrary
combination with any number of other test cases.

The simplest test case subclass will simply override the `runTest()'
method in order to perform specific testing code:

     import unittest
     
     class DefaultWidgetSizeTestCase(unittest.TestCase):
         def runTest(self):
             widget = Widget("The widget")
             self.failUnless(widget.size() == (50,50), 'incorrect default size')

Note that in order to test something, we use the one of the `assert*()'
or `fail*()' methods provided by the `TestCase' base class.  If the
test fails when the test case runs, an exception will be raised, and
the testing framework will identify the test case as a "failure".
Other exceptions that do not arise from checks made through the
`assert*()' and `fail*()' methods are identified by the testing
framework as dfn{errors}.

The way to run a test case will be described later.  For now, note that
to construct an instance of such a test case, we call its constructor
without arguments:

     testCase = DefaultWidgetSizeTestCase()

Now, such test cases can be numerous, and their set-up can be
repetitive.  In the above case, constructing a "Widget" in each of 100
Widget test case subclasses would mean unsightly duplication.

Luckily, we can factor out such set-up code by implementing a method
called `setUp()', which the testing framework will automatically call
for us when we run the test:

     import unittest
     
     class SimpleWidgetTestCase(unittest.TestCase):
         def setUp(self):
             self.widget = Widget("The widget")
     
     class DefaultWidgetSizeTestCase(SimpleWidgetTestCase):
         def runTest(self):
             self.failUnless(self.widget.size() == (50,50),
                             'incorrect default size')
     
     class WidgetResizeTestCase(SimpleWidgetTestCase):
         def runTest(self):
             self.widget.resize(100,150)
             self.failUnless(self.widget.size() == (100,150),
                             'wrong size after resize')

If the `setUp()' method raises an exception while the test is running,
the framework will consider the test to have suffered an error, and the
`runTest()' method will not be executed.

Similarly, we can provide a `tearDown()' method that tidies up after
the `runTest()' method has been run:

     import unittest
     
     class SimpleWidgetTestCase(unittest.TestCase):
         def setUp(self):
             self.widget = Widget("The widget")
     
         def tearDown(self):
             self.widget.dispose()
             self.widget = None

If `setUp()' succeeded, the `tearDown()' method will be run regardless
of whether or not `runTest()' succeeded.

Such a working environment for the testing code is called a "fixture".

Often, many small test cases will use the same fixture.  In this case,
we would end up subclassing `SimpleWidgetTestCase' into many small
one-method classes such as `DefaultWidgetSizeTestCase'.  This is
time-consuming and discouraging, so in the same vein as JUnit, PyUnit
provides a simpler mechanism:

     import unittest
     
     class WidgetTestCase(unittest.TestCase):
         def setUp(self):
             self.widget = Widget("The widget")
     
         def tearDown(self):
             self.widget.dispose()
             self.widget = None
     
         def testDefaultSize(self):
             self.failUnless(self.widget.size() == (50,50),
                             'incorrect default size')
     
         def testResize(self):
             self.widget.resize(100,150)
             self.failUnless(self.widget.size() == (100,150),
                             'wrong size after resize')

Here we have not provided a `runTest()' method, but have instead
provided two different test methods.  Class instances will now each run
one of the `test*()'  methods, with `self.widget' created and destroyed
separately for each instance.  When creating an instance we must
specify the test method it is to run.  We do this by passing the method
name in the constructor:

     defaultSizeTestCase = WidgetTestCase("testDefaultSize")
     resizeTestCase = WidgetTestCase("testResize")

Test case instances are grouped together according to the features they
test.  PyUnit provides a mechanism for this: the `test suite',
represented by the class `TestSuite' in the `unittest' module:

     widgetTestSuite = unittest.TestSuite()
     widgetTestSuite.addTest(WidgetTestCase("testDefaultSize"))
     widgetTestSuite.addTest(WidgetTestCase("testResize"))

For the ease of running tests, as we will see later, it is a good idea
to provide in each test module a callable object that returns a
pre-built test suite:

     def suite():
         suite = unittest.TestSuite()
         suite.addTest(WidgetTestCase("testDefaultSize"))
         suite.addTest(WidgetTestCase("testResize"))
         return suite

or even:

     class WidgetTestSuite(unittest.TestSuite):
         def __init__(self):
             unittest.TestSuite.__init__(self,map(WidgetTestCase,
                                                   ("testDefaultSize",
                                                    "testResize")))

(The latter is admittedly not for the faint-hearted!)

Since it is a common pattern to create a `TestCase' subclass with many
similarly named test functions, there is a convenience function called
`makeSuite()' provided in the `unittest' module that constructs a test
suite that comprises all of the test cases in a test case class:

     suite = unittest.makeSuite(WidgetTestCase,'test')

Note that when using the `makeSuite()' function, the order in which the
various test cases will be run by the test suite is the order
determined by sorting the test function names using the `cmp()'
built-in function.

Often it is desirable to group suites of test cases together, so as to
run tests for the whole system at once.  This is easy, since
`TestSuite' instances can be added to a `TestSuite' just as `TestCase'
instances can be added to a `TestSuite':

     suite1 = module1.TheTestSuite()
     suite2 = module2.TheTestSuite()
     alltests = unittest.TestSuite((suite1, suite2))

You can place the definitions of test cases and test suites in the same
modules as the code they are to test (such as `widget.py'), but there
are several advantages to placing the test code in a separate module,
such as `widgettests.py':

   * The test module can be run standalone from the command line.

   * The test code can more easily be separated from shipped code.

   * There is less temptation to change test code to fit the code it
     tests without a good reason.

   * Test code should be modified much less frequently than the code it
     tests.

   * Tested code can be refactored more easily.

   * Tests for modules written in C must be in separate modules anyway,
     so why not be consistent?

   * If the testing strategy changes, there is no need to change the
     source code.


File: python-lib.info,  Node: Re-using old test code,  Next: Classes and functions 2,  Prev: Organizing test code,  Up: unittest

Re-using old test code
----------------------

Some users will find that they have existing test code that they would
like to run from PyUnit, without converting every old test function to
a `TestCase' subclass.

For this reason, PyUnit provides a `FunctionTestCase' class.  This
subclass of `TestCase' can be used to wrap an existing test function.
Set-up and tear-down functions can also optionally be wrapped.

Given the following test function:

     def testSomething():
         something = makeSomething()
         assert something.name is not None
         # ...

one can create an equivalent test case instance as follows:

     testcase = unittest.FunctionTestCase(testSomething)

If there are additional set-up and tear-down methods that should be
called as part of the test case's operation, they can also be provided:

     testcase = unittest.FunctionTestCase(testSomething,
                                          setUp=makeSomethingDB,
                                          tearDown=deleteSomethingDB)

_Note:_ PyUnit supports the use of `AssertionError' as an indicator of
test failure, but does not recommend it.  Future versions may treat
`AssertionError' differently.


File: python-lib.info,  Node: Classes and functions 2,  Next: TestCase Objects,  Prev: Re-using old test code,  Up: unittest

Classes and functions
---------------------

`TestCase()'
     Instances of the `TestCase' class represent the smallest testable
     units in a set of tests.  This class is intended to be used as a
     base class, with specific tests being implemented by concrete
     subclasses.  This class implements the interface needed by the test
     runner to allow it to drive the test, and methods that the test
     code can use to check for and report various kinds of failures.

`FunctionTestCase(testFunc[, setUp[, tearDown[, description]]])'
     This class implements the portion of the `TestCase' interface
     which allows the test runner to drive the test, but does not
     provide the methods which test code can use to check and report
     errors.  This is used to create test cases using legacy test code,
     allowing it to be integrated into a `unittest'-based test
     framework.

`TestSuite([tests])'
     This class represents an aggregation of individual tests cases and
     test suites.  The class presents the interface needed by the test
     runner to allow it to be run as any other test case, but all the
     contained tests and test suites are executed.  Additional methods
     are provided to add test cases and suites to the aggregation.  If
     TESTS is given, it must be a sequence of individual tests that
     will be added to the suite.

`TestLoader()'
     This class is responsible for loading tests according to various
     criteria and returning them wrapped in a `TestSuite'.  It can load
     all tests within a given module or `TestCase' class.  When loading
     from a module, it considers all `TestCase'-derived classes.  For
     each such class, it creates an instance for each method with a
     name beginning with the string `test'.

`defaultTestLoader'
     Instance of the `TestLoader' class which can be shared.  If no
     customization of the `TestLoader' is needed, this instance can
     always be used instead of creating new instances.

`TextTestRunner([stream[, descriptions[, verbosity]]])'
     A basic test runner implementation which prints results on standard
     output.  It has a few configurable parameters, but is essentially
     very simple.  Graphical applications which run test suites should
     provide alternate implementations.

`main([module[, defaultTest[, argv[, testRunner[, testRunner]]]]])'
     A command-line program that runs a set of tests; this is primarily
     for making test modules conveniently executable.  The simplest use
     for this function is:

          if __name__ == '__main__':
              unittest.main()

In some cases, the existing tests may have be written using the
`doctest' module.  If so, that module provides a `DocTestSuite' class
that can automatically build `unittest.TestSuite' instances from the
existing test code.  _Added in Python version 2.3_


File: python-lib.info,  Node: TestCase Objects,  Next: TestSuite Objects,  Prev: Classes and functions 2,  Up: unittest

TestCase Objects
----------------

Each `TestCase' instance represents a single test, but each concrete
subclass may be used to define multiple tests -- the concrete class
represents a single test fixture.  The fixture is created and cleaned
up for each test case.

`TestCase' instances provide three groups of methods: one group used to
run the test, another used by the test implementation to check
conditions and report failures, and some inquiry methods allowing
information about the test itself to be gathered.

Methods in the first group are:

`setUp()'
     Method called to prepare the test fixture.  This is called
     immediately before calling the test method; any exception raised by
     this method will be considered an error rather than a test failure.
     The default implementation does nothing.

`tearDown()'
     Method called immediately after the test method has been called and
     the result recorded.  This is called even if the test method raised
     an exception, so the implementation in subclasses may need to be
     particularly careful about checking internal state.  Any exception
     raised by this method will be considered an error rather than a
     test failure.  This method will only be called if the `setUp()'
     succeeds, regardless of the outcome of the test method.  The
     default implementation does nothing.

`run([result])'
     Run the test, collecting the result into the test result object
     passed as RESULT.  If RESULT is omitted or `None', a temporary
     result object is created and used, but is not made available to
     the caller.  This is equivalent to simply calling the `TestCase'
     instance.

`debug()'
     Run the test without collecting the result.  This allows exceptions
     raised by the test to be propogated to the caller, and can be used
     to support running tests under a debugger.

The test code can use any of the following methods to check for and
report failures.

`assert_(expr[, msg])'

`failUnless(expr[, msg])'
     Signal a test failure if EXPR is false; the explanation for the
     error will be MSG if given, otherwise it will be `None'.

`assertEqual(first, second[, msg])'

`failUnlessEqual(first, second[, msg])'
     Test that FIRST and SECOND are equal.  If the values do not
     compare equal, the test will fail with the explanation given by
     MSG, or `None'.  Note that using `failUnlessEqual()' improves upon
     doing the comparison as the first parameter to `failUnless()':
     the default value for MSG can be computed to include
     representations of both FIRST and SECOND.

`assertNotEqual(first, second[, msg])'

`failIfEqual(first, second[, msg])'
     Test that FIRST and SECOND are not equal.  If the values do
     compare equal, the test will fail with the explanation given by
     MSG, or `None'.  Note that using `failIfEqual()' improves upon
     doing the comparison as the first parameter to `failUnless()' is
     that the default value for MSG can be computed to include
     representations of both FIRST and SECOND.

`assertAlmostEqual(first, second[, places[, msg]])'

`failUnlessAlmostEqual(first, second[, places[, msg]])'
     Test that FIRST and SECOND are approximately equal by computing
     the difference, rounding to the given number of PLACES, and
     comparing to zero.  Note that comparing a given number of decimal
     places is not the same as comparing a given number of significant
     digits.  If the values do not compare equal, the test will fail
     with the explanation given by MSG, or `None'.

`assertNotAlmostEqual(first, second[, places[, msg]])'

`failIfAlmostEqual(first, second[, places[, msg]])'
     Test that FIRST and SECOND are not approximately equal by
     computing the difference, rounding to the given number of PLACES,
     and comparing to zero.  Note that comparing a given number of
     decimal places is not the same as comparing a given number of
     significant digits.  If the values do not compare equal, the test
     will fail with the explanation given by MSG, or `None'.

`assertRaises(exception, callable, ...)'

`failUnlessRaises(exception, callable, ...)'
     Test that an exception is raised when CALLABLE is called with any
     positional or keyword arguments that are also passed to
     `assertRaises()'.  The test passes if EXCEPTION is raised, is an
     error if another exception is raised, or fails if no exception is
     raised.  To catch any of a group of exceptions, a tuple containing
     the exception classes may be passed as EXCEPTION.

`failIf(expr[, msg])'
     The inverse of the `failUnless()' method is the `failIf()' method.
     This signals a test failure if EXPR is true, with MSG or `None'
     for the error message.

`fail([msg])'
     Signals a test failure unconditionally, with MSG or `None' for the
     error message.

`failureException'
     This class attribute gives the exception raised by the `test()'
     method.  If a test framework needs to use a specialized exception,
     possibly to carry additional information, it must subclass this
     exception in order to "play fair" with the framework.  The initial
     value of this attribute is `AssertionError'.

Testing frameworks can use the following methods to collect information
on the test:

`countTestCases()'
     Return the number of tests represented by the this test object.
     For `TestCase' instances, this will always be `1', but this method
     is also implemented by the `TestSuite' class, which can return
     larger values.

`defaultTestResult()'
     Return the default type of test result object to be used to run
     this test.

`id()'
     Return a string identifying the specific test case.  This is
     usually the full name of the test method, including the module and
     class names.

`shortDescription()'
     Returns a one-line description of the test, or `None' if no
     description has been provided.  The default implementation of this
     method returns the first line of the test method's docstring, if
     available, or `None'.


File: python-lib.info,  Node: TestSuite Objects,  Next: TestResult Objects,  Prev: TestCase Objects,  Up: unittest

TestSuite Objects
-----------------

`TestSuite' objects behave much like `TestCase' objects, except they do
not actually implement a test.  Instead, they are used to aggregate
tests into groups that should be run together.  Some additional methods
are available to add tests to `TestSuite' instances:

`addTest(test)'
     Add a `TestCase' or `TestSuite' to the set of tests that make up
     the suite.

`addTests(tests)'
     Add all the tests from a sequence of `TestCase' and `TestSuite'
     instances to this test suite.

The `run()' method is also slightly different:

`run(result)'
     Run the tests associated with this suite, collecting the result
     into the test result object passed as RESULT.  Note that unlike
     `TestCase.run()', `TestSuite.run()' requires the result object to
     be passed in.

In the typical usage of a `TestSuite' object, the `run()' method is
invoked by a `TestRunner' rather than by the end-user test harness.


File: python-lib.info,  Node: TestResult Objects,  Next: TestLoader Objects,  Prev: TestSuite Objects,  Up: unittest

TestResult Objects
------------------

A `TestResult' object stores the results of a set of tests.  The
`TestCase' and `TestSuite' classes ensure that results are properly
stored; test authors do not need to worry about recording the outcome
of tests.

Testing frameworks built on top of `unittest' may want access to the
`TestResult' object generated by running a set of tests for reporting
purposes; a `TestResult' instance is returned by the `TestRunner.run()'
method for this purpose.

Each instance holds the total number of tests run, and collections of
failures and errors that occurred among those test runs.  The
collections contain tuples of `(TESTCASE, TRACEBACK)', where TRACEBACK
is a string containing a formatted version of the traceback for the
exception.

`TestResult' instances have the following attributes that will be of
interest when inspecting the results of running a set of tests:

`errors'
     A list containing pairs of `TestCase' instances and the formatted
     tracebacks for tests which raised an exception but did not signal
     a test failure.  _Changed in Python version 2.2_

`failures'
     A list containing pairs of `TestCase' instances and the formatted
     tracebacks for tests which signalled a failure in the code under
     test.  _Changed in Python version 2.2_

`testsRun'
     The number of tests which have been started.

`wasSuccessful()'
     Returns true if all tests run so far have passed, otherwise returns
     false.

The following methods of the `TestResult' class are used to maintain
the internal data structures, and may be extended in subclasses to
support additional reporting requirements.  This is particularly useful
in building tools which support interactive reporting while tests are
being run.

`startTest(test)'
     Called when the test case TEST is about to be run.

`stopTest(test)'
     Called when the test case TEST has been executed, regardless of
     the outcome.

`addError(test, err)'
     Called when the test case TEST raises an exception without
     signalling a test failure.  ERR is a tuple of the form returned by
     `sys.exc_info()':  `(TYPE, VALUE, TRACEBACK)'.

`addFailure(test, err)'
     Called when the test case TEST signals a failure.  ERR is a tuple
     of the form returned by `sys.exc_info()':  `(TYPE, VALUE,
     TRACEBACK)'.

`addSuccess(test)'
     This method is called for a test that does not fail; TEST is the
     test case object.

One additional method is available for `TestResult' objects:

`stop()'
     This method can be called to signal that the set of tests being run
     should be aborted.  Once this has been called, the `TestRunner'
     object return to its caller without running any additional tests.
     This is used by the `TextTestRunner' class to stop the test
     framework when the user signals an interrupt from the keyboard.
     Interactive tools which provide runners can use this in a similar
     manner.


File: python-lib.info,  Node: TestLoader Objects,  Next: Getting Extended Error Information,  Prev: TestResult Objects,  Up: unittest

TestLoader Objects
------------------

The `TestLoader' class is used to create test suites from classes and
modules.  Normally, there is no need to create an instance of this
class; the `unittest' module provides an instance that can be shared as
the `defaultTestLoader' module attribute.  Using a subclass or instance
would allow customization of some configurable properties.

`TestLoader' objects have the following methods:

`loadTestsFromTestCase(testCaseClass)'
     Return a suite of all tests cases contained in the
     `TestCase'-derived class `testCaseClass'.

`loadTestsFromModule(module)'
     Return a suite of all tests cases contained in the given module.
     This method searches MODULE for classes derived from `TestCase'
     and creates an instance of the class for each test method defined
     for the class.

     _While using a hierarchy of `Testcase'-derived classes can be
     convenient in sharing fixtures and helper functions, defining test
     methods on base classes that are not intended to be instantiated
     directly does not play well with this method.  Doing so, however,
     can be useful when the fixtures are different and defined in
     subclasses._

`loadTestsFromName(name[, module])'
     Return a suite of all tests cases given a string specifier.

     The specifier NAME is a "dotted name" that may resolve either to a
     module, a test case class, a test method within a test case class,
     or a callable object which returns a `TestCase' or `TestSuite'
     instance.  For example, if you have a module `SampleTests'
     containing a `TestCase'-derived class `SampleTestCase' with three
     test methods (`test_one()', `test_two()', and `test_three()'), the
     specifier `'SampleTests.SampleTestCase'' would cause this method to
     return a suite which will run all three test methods.  Using the
     specifier `'SampleTests.SampleTestCase.test_two'' would cause it
     to return a test suite which will run only the `test_two()' test
     method.  The specifier can refer to modules and packages which
     have not been imported; they will be imported as a side-effect.

     The method optionally resolves NAME relative to a given module.

`loadTestsFromNames(names[, module])'
     Similar to `loadTestsFromName()', but takes a sequence of names
     rather than a single name.  The return value is a test suite which
     supports all the tests defined for each name.

`getTestCaseNames(testCaseClass)'
     Return a sorted sequence of method names found within
     TESTCASECLASS.

The following attributes of a `TestLoader' can be configured either by
subclassing or assignment on an instance:

`testMethodPrefix'
     String giving the prefix of method names which will be interpreted
     as test methods.  The default value is `'test''.

`sortTestMethodsUsing'
     Function to be used to compare method names when sorting them in
     `getTestCaseNames()'.  The default value is the built-in `cmp()'
     function; it can be set to `None' to disable the sort.

`suiteClass'
     Callable object that constructs a test suite from a list of tests.
     No methods on the resulting object are needed.  The default value
     is the `TestSuite' class.


File: python-lib.info,  Node: Getting Extended Error Information,  Prev: TestLoader Objects,  Up: unittest

Getting Extended Error Information
----------------------------------

Some applications can make use of more error information (for example,
an integrated development environment, or IDE).  Such an application
can retrieve supplemental information about errors and failures by
using an alternate `TestResult' implementation, and extending the
`defaultTestResult()' method of the `TestCase' class to provide it.

Here is a brief example of a `TestResult' subclass which stores the
actual exception and traceback objects.  (Be aware that storing
traceback objects can cause a great deal of memory not to be reclaimed
when it otherwise would be, which can have effects that affect the
behavior of the tests.)

     import unittest
     
     class MyTestCase(unittest.TestCase):
         def defaultTestResult(self):
             return MyTestResult()
     
     class MyTestResult(unittest.TestResult):
         def __init__(self):
             self.errors_tb = []
             self.failures_tb = []
     
         def addError(self, test, err):
             self.errors_tb.append((test, err))
             unittest.TestResult.addError(self, test, err)
     
         def addFailure(self, test, err):
             self.failures_tb.append((test, err))
             unittest.TestResult.addFailure(self, test, err)

Tests written using `MyTestCase' as the base class, instead of
`TestCase', will allow tools to extract additional information from the
results object.


File: python-lib.info,  Node: test,  Next: testtest_support,  Prev: unittest,  Up: Miscellaneous Services

Regression tests package for Python
===================================

Regression tests package containing the testing suite for Python.

The `test' package contains all regression tests for Python as well as
the modules `test.test_support' and `test.regrtest'.
`test.test_support' is used to enhance your tests while `test.regrtest'
drives the testing suite.

Each module in the `test' package whose name starts with `test_' is a
testing suite for a specific module or feature.  All new tests should
be written using the `unittest' module; using `unittest' is not
required but makes the tests more flexible and maintenance of the tests
easier.  Some older tests are written to use `doctest' and a
"traditional" testing style; these styles of tests will not be covered.

See also:
     *Note unittest:: Writing PyUnit regression tests.  *Note doctest::
     Tests embedded in documentation strings.

* Menu:

* Writing Unit Tests for the test package::
* Running tests Using testregrtest::


File: python-lib.info,  Node: Writing Unit Tests for the test package,  Next: Running tests Using testregrtest,  Prev: test,  Up: test

Writing Unit Tests for the `test' package
-----------------------------------------

It is preferred that tests for the `test' package use the `unittest'
module and follow a few guidelines.  One is to have the name of all the
test methods start with `'test_'' as well as the module's name.  This
is needed so that the methods are recognized by the test driver as test
methods.  Also, no documentation string for the method should be
included.  A comment (such as `# Tests function returns only True or
False') should be used to provide documentation for test methods.  This
is done because documentation strings get printed out if they exist and
thus what test is being run is not stated.

A basic boilerplate is often used:

     import unittest
     from test import test_support
     
     class MyTestCase1(unittest.TestCase):
     
         # Only use setUp() and tearDown() if necessary
     
         def setUp(self):
             ... code to execute in preparation for tests ...
     
         def tearDown(self):
             ... code to execute to clean up after tests ...
     
         def test_feature_one(self):
             # Test feature one.
             ... testing code ...
     
         def test_feature_two(self):
             # Test feature two.
             ... testing code ...
     
         ... more test methods ...
     
     class MyTestCase2(unittest.TestCase):
         ... same structure as MyTestCase1 ...
     
     ... more test classes ...
     
     def test_main():
         test_support.run_unittest(MyTestCase1,
                                   MyTestCase2,
                                   ... list other tests ...
                                  )
     
     if __name__ == '__main__':
         test_main()

This boilerplate code allows the testing suite to be run by
`test.regrtest' as well as on its own as a script.

The goal for regression testing is to try to break code.  This leads to
a few guidelines to be followed:

   * The testing suite should exercise all classes, functions, and
     constants.  This includes not just the external API that is to be
     presented to the outside world but also "private" code.

   * Whitebox testing (examining the code being tested when the tests
     are being written) is preferred.  Blackbox testing (testing only
     the published user interface) is not complete enough to make sure
     all boundary and edge cases are tested.

   * Make sure all possible values are tested including invalid ones.
     This makes sure that not only all valid values are acceptable but
     also that improper values are handled correctly.

   * Exhaust as many code paths as possible.  Test where branching
     occurs and thus tailor input to make sure as many different paths
     through the code are taken.

   * Add an explicit test for any bugs discovered for the tested code.
     This will make sure that the error does not crop up again if the
     code is changed in the future.

   * Make sure to clean up after your tests (such as close and remove
     all temporary files).

   * Import as few modules as possible and do it as soon as possible.
     This minimizes external dependencies of tests and also minimizes
     possible anomalous behavior from side-effects of importing a
     module.

   * Try to maximize code reuse.  On occasion, tests will vary by
     something as small as what type of input is used.  Minimize code
     duplication by subclassing a basic test class with a class that
     specifies the input:
          class TestFuncAcceptsSequences(unittest.TestCase):
          
              func = mySuperWhammyFunction
          
              def test_func(self):
                  self.func(self.arg)
          
          class AcceptLists(TestFuncAcceptsSequences):
              arg = [1,2,3]
          
          class AcceptStrings(TestFuncAcceptsSequences):
              arg = 'abc'
          
          class AcceptTuples(TestFuncAcceptsSequences):
              arg = (1,2,3)


See also:
     `Test Driven Development' {A book by Kent Beck on writing tests
     before code.}


File: python-lib.info,  Node: Running tests Using testregrtest,  Prev: Writing Unit Tests for the test package,  Up: test

Running tests Using `test.regrtest'
-----------------------------------

`test.regrtest' can be used as a script to drive Python's regression
test suite.  Running the script by itself automatically starts running
all regression tests in the `test' package.  It does this by finding
all modules in the package whose name starts with `test_', importing
them, and executing the function `test_main()' if present.  The names
of tests to execute may also be passed to the script.  Specifying a
single regression test (`python regrtest.py' `test_spam.py') will
minimize output and only print whether the test passed or failed and
thus minimize output.

Running `test.regrtest' directly allows what resources are available
for tests to use to be set.  You do this by using the `-u' command-line
option.  Run `python regrtest.py' `-uall' to turn on all resources;
specifying `all' as an option for `-u' enables all possible resources.
If all but one resource is desired (a more common case), a
comma-separated list of resources that are not desired may be listed
after `all'.  The command `python regrtest.py'
`-uall,-audio,-largefile' will run `test.regrtest' with all resources
except the `audio' and `largefile' resources.  For a list of all
resources and more command-line options, run `python regrtest.py' `-h'.

Some other ways to execute the regression tests depend on what platform
the tests are being executed on.  On UNIX, you can run `make' `test' at
the top-level directory where Python was built.  On Windows, executing
`rt.bat' from your `PCBuild' directory will run all regression tests.

