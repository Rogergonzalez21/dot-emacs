This is python-lib.info, produced by makeinfo version 4.3 from
python-lib.texi.

October 3, 2003


File: python-lib.info,  Node: Codec Base Classes,  Next: Standard Encodings,  Prev: codecs,  Up: codecs

Codec Base Classes
------------------

The `codecs' defines a set of base classes which define the interface
and can also be used to easily write you own codecs for use in Python.

Each codec has to define four interfaces to make it usable as codec in
Python: stateless encoder, stateless decoder, stream reader and stream
writer. The stream reader and writers typically reuse the stateless
encoder/decoder to implement the file protocols.

The `Codec' class defines the interface for stateless encoders/decoders.

To simplify and standardize error handling, the `encode()' and
`decode()' methods may implement different error handling schemes by
providing the ERRORS string argument.  The following string values are
defined and implemented by all standard Python codecs:

Value                                Meaning
------                               -----
'strict'                             Raise `UnicodeError' (or a
                                     subclass); this is the default.
'ignore'                             Ignore the character and continue
                                     with the next.
'replace'                            Replace with a suitable replacement
                                     character; Python will use the
                                     official U+FFFD REPLACEMENT
                                     CHARACTER for the built-in Unicode
                                     codecs on decoding and '?' on
                                     encoding.
'xmlcharrefreplace'                  Replace with the appropriate XML
                                     character reference (only for
                                     encoding).
'backslashreplace'                   Replace with backslashed escape
                                     sequences (only for encoding).

The set of allowed values can be extended via `register_error'.

* Menu:

* Codec Objects::
* StreamWriter Objects::
* StreamReader Objects::
* StreamReaderWriter Objects::
* StreamRecoder Objects::


File: python-lib.info,  Node: Codec Objects,  Next: StreamWriter Objects,  Prev: Codec Base Classes,  Up: Codec Base Classes

Codec Objects
.............

The `Codec' class defines these methods which also define the function
interfaces of the stateless encoder and decoder:

`encode(input[, errors])'
     Encodes the object INPUT and returns a tuple (output object,
     length consumed).  While codecs are not restricted to use with
     Unicode, in a Unicode context, encoding converts a Unicode object
     to a plain string using a particular character set encoding (e.g.,
     `cp1252' or `iso-8859-1').

     ERRORS defines the error handling to apply. It defaults to
     `'strict'' handling.

     The method may not store state in the `Codec' instance. Use
     `StreamCodec' for codecs which have to keep state in order to make
     encoding/decoding efficient.

     The encoder must be able to handle zero length input and return an
     empty object of the output object type in this situation.

`decode(input[, errors])'
     Decodes the object INPUT and returns a tuple (output object,
     length consumed).  In a Unicode context, decoding converts a plain
     string encoded using a particular character set encoding to a
     Unicode object.

     INPUT must be an object which provides the `bf_getreadbuf' buffer
     slot.  Python strings, buffer objects and memory mapped files are
     examples of objects providing this slot.

     ERRORS defines the error handling to apply. It defaults to
     `'strict'' handling.

     The method may not store state in the `Codec' instance. Use
     `StreamCodec' for codecs which have to keep state in order to make
     encoding/decoding efficient.

     The decoder must be able to handle zero length input and return an
     empty object of the output object type in this situation.

The `StreamWriter' and `StreamReader' classes provide generic working
interfaces which can be used to implement new encodings submodules very
easily. See `encodings.utf_8' for an example on how this is done.


File: python-lib.info,  Node: StreamWriter Objects,  Next: StreamReader Objects,  Prev: Codec Objects,  Up: Codec Base Classes

StreamWriter Objects
....................

The `StreamWriter' class is a subclass of `Codec' and defines the
following methods which every stream writer must define in order to be
compatible to the Python codec registry.

`StreamWriter(stream[, errors])'
     Constructor for a `StreamWriter' instance.

     All stream writers must provide this constructor interface. They
     are free to add additional keyword arguments, but only the ones
     defined here are used by the Python codec registry.

     STREAM must be a file-like object open for writing (binary) data.

     The `StreamWriter' may implement different error handling schemes
     by providing the ERRORS keyword argument. These parameters are
     predefined:

        * `'strict'' Raise `ValueError' (or a subclass); this is the
          default.

        * `'ignore'' Ignore the character and continue with the next.

        * `'replace'' Replace with a suitable replacement character

        * `'xmlcharrefreplace'' Replace with the appropriate XML
          character reference

        * `'backslashreplace'' Replace with backslashed escape
          sequences.

     The ERRORS argument will be assigned to an attribute of the same
     name. Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the `StreamWriter' object.

     The set of allowed values for the ERRORS argument can be extended
     with `register_error()'.

`write(object)'
     Writes the object's contents encoded to the stream.

`writelines(list)'
     Writes the concatenated list of strings to the stream (possibly by
     reusing the `write()' method).

`reset()'
     Flushes and resets the codec buffers used for keeping state.

     Calling this method should ensure that the data on the output is
     put into a clean state, that allows appending of new fresh data
     without having to rescan the whole stream to recover state.

In addition to the above methods, the `StreamWriter' must also inherit
all other methods and attribute from the underlying stream.


File: python-lib.info,  Node: StreamReader Objects,  Next: StreamReaderWriter Objects,  Prev: StreamWriter Objects,  Up: Codec Base Classes

StreamReader Objects
....................

The `StreamReader' class is a subclass of `Codec' and defines the
following methods which every stream reader must define in order to be
compatible to the Python codec registry.

`StreamReader(stream[, errors])'
     Constructor for a `StreamReader' instance.

     All stream readers must provide this constructor interface. They
     are free to add additional keyword arguments, but only the ones
     defined here are used by the Python codec registry.

     STREAM must be a file-like object open for reading (binary) data.

     The `StreamReader' may implement different error handling schemes
     by providing the ERRORS keyword argument. These parameters are
     defined:

        * `'strict'' Raise `ValueError' (or a subclass); this is the
          default.

        * `'ignore'' Ignore the character and continue with the next.

        * `'replace'' Replace with a suitable replacement character.

     The ERRORS argument will be assigned to an attribute of the same
     name. Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the `StreamReader' object.

     The set of allowed values for the ERRORS argument can be extended
     with `register_error()'.

`read([size])'
     Decodes data from the stream and returns the resulting object.

     SIZE indicates the approximate maximum number of bytes to read
     from the stream for decoding purposes. The decoder can modify this
     setting as appropriate. The default value -1 indicates to read and
     decode as much as possible.  SIZE is intended to prevent having to
     decode huge files in one step.

     The method should use a greedy read strategy meaning that it should
     read as much data as is allowed within the definition of the
     encoding and the given size, e.g.  if optional encoding endings or
     state markers are available on the stream, these should be read
     too.

`readline([size])'
     Read one line from the input stream and return the decoded data.

     Unlike the `readlines()' method, this method inherits the line
     breaking knowledge from the underlying stream's `readline()'
     method - there is currently no support for line breaking using the
     codec decoder due to lack of line buffering.  Sublcasses should
     however, if possible, try to implement this method using their own
     knowledge of line breaking.

     SIZE, if given, is passed as size argument to the stream's
     `readline()' method.

`readlines([sizehint])'
     Read all lines available on the input stream and return them as
     list of lines.

     Line breaks are implemented using the codec's decoder method and
     are included in the list entries.

     SIZEHINT, if given, is passed as SIZE argument to the stream's
     `read()' method.

`reset()'
     Resets the codec buffers used for keeping state.

     Note that no stream repositioning should take place.  This method
     is primarily intended to be able to recover from decoding errors.

In addition to the above methods, the `StreamReader' must also inherit
all other methods and attribute from the underlying stream.

The next two base classes are included for convenience. They are not
needed by the codec registry, but may provide useful in practice.


File: python-lib.info,  Node: StreamReaderWriter Objects,  Next: StreamRecoder Objects,  Prev: StreamReader Objects,  Up: Codec Base Classes

StreamReaderWriter Objects
..........................

The `StreamReaderWriter' allows wrapping streams which work in both
read and write modes.

The design is such that one can use the factory functions returned by
the `lookup()' function to construct the instance.

`StreamReaderWriter(stream, Reader, Writer, errors)'
     Creates a `StreamReaderWriter' instance.  STREAM must be a
     file-like object.  READER and WRITER must be factory functions or
     classes providing the `StreamReader' and `StreamWriter' interface
     resp.  Error handling is done in the same way as defined for the
     stream readers and writers.

`StreamReaderWriter' instances define the combined interfaces of
`StreamReader' and `StreamWriter' classes. They inherit all other
methods and attribute from the underlying stream.


File: python-lib.info,  Node: StreamRecoder Objects,  Prev: StreamReaderWriter Objects,  Up: Codec Base Classes

StreamRecoder Objects
.....................

The `StreamRecoder' provide a frontend - backend view of encoding data
which is sometimes useful when dealing with different encoding
environments.

The design is such that one can use the factory functions returned by
the `lookup()' function to construct the instance.

`StreamRecoder(stream, encode, decode, Reader, Writer, errors)'
     Creates a `StreamRecoder' instance which implements a two-way
     conversion: ENCODE and DECODE work on the frontend (the input to
     `read()' and output of `write()') while READER and WRITER work on
     the backend (reading and writing to the stream).

     You can use these objects to do transparent direct recodings from
     e.g. Latin-1 to UTF-8 and back.

     STREAM must be a file-like object.

     ENCODE, DECODE must adhere to the `Codec' interface, READER,
     WRITER must be factory functions or classes providing objects of
     the `StreamReader' and `StreamWriter' interface respectively.

     ENCODE and DECODE are needed for the frontend translation, READER
     and WRITER for the backend translation.  The intermediate format
     used is determined by the two sets of codecs, e.g. the Unicode
     codecs will use Unicode as intermediate encoding.

     Error handling is done in the same way as defined for the stream
     readers and writers.

`StreamRecoder' instances define the combined interfaces of
`StreamReader' and `StreamWriter' classes. They inherit all other
methods and attribute from the underlying stream.


File: python-lib.info,  Node: Standard Encodings,  Next: encodingsidna --- Internationalized Domain Names in Applications,  Prev: Codec Base Classes,  Up: codecs

Standard Encodings
------------------

Python comes with a number of codecs builtin, either implemented as C
functions, or with dictionaries as mapping tables. The following table
lists the codecs by name, together with a few common aliases, and the
languages for which the encoding is likely used. Neither the list of
aliases nor the list of languages is meant to be exhaustive. Notice
that spelling alternatives that only differ in case or use a hyphen
instead of an underscore are also valid aliases.

Many of the character sets support the same languages. They vary in
individual characters (e.g. whether the EURO SIGN is supported or not),
and in the assignment of characters to code positions. For the European
languages in particular, the following variants typically exist:

   * an ISO 8859 codeset

   * a Microsoft Windows code page, which is typically derived from a
     8859 codeset, but replaces control characters with additional
     graphic characters

   * an IBM EBCDIC code page

   * an IBM PC code page, which is ASCII compatible

Codec                    Aliases                  Languages
------                   -----                    -----
ascii                    646, us-ascii            English
cp037                    IBM037, IBM039           English
cp424                    EBCDIC-CP-HE, IBM424     Hebrew
cp437                    437, IBM437              English
cp500                    EBCDIC-CP-BE,            Western Europe
                         EBCDIC-CP-CH, IBM500     
cp737                                             Greek
cp775                    IBM775                   Baltic languages
cp850                    850, IBM850              Western Europe
cp852                    852, IBM852              Central and Eastern
                                                  Europe
cp855                    855, IBM855              Bulgarian,
                                                  Byelorussian,
                                                  Macedonian, Russian,
                                                  Serbian
cp856                                             Hebrew
cp857                    857, IBM857              Turkish
cp860                    860, IBM860              Portuguese
cp861                    861, CP-IS, IBM861       Icelandic
cp862                    862, IBM862              Hebrew
cp863                    863, IBM863              Canadian
cp864                    IBM864                   Arabic
cp865                    865, IBM865              Danish, Norwegian
cp869                    869, CP-GR, IBM869       Greek
cp874                                             Thai
cp875                                             Greek
cp1006                                            Urdu
cp1026                   ibm1026                  Turkish
cp1140                   ibm1140                  Western Europe
cp1250                   windows-1250             Central and Eastern
                                                  Europe
cp1251                   windows-1251             Bulgarian,
                                                  Byelorussian,
                                                  Macedonian, Russian,
                                                  Serbian
cp1252                   windows-1252             Western Europe
cp1253                   windows-1253             Greek
cp1254                   windows-1254             Turkish
cp1255                   windows-1255             Hebrew
cp1256                   windows1256              Arabic
cp1257                   windows-1257             Baltic languages
cp1258                   windows-1258             Vietnamese
latin_1                  iso-8859-1, iso8859-1,   West Europe
                         8859, cp819, latin,      
                         latin1, L1               
iso8859_2                iso-8859-2, latin2, L2   Central and Eastern
                                                  Europe
iso8859_3                iso-8859-3, latin3, L3   Esperanto, Maltese
iso8859_4                iso-8859-4, latin4, L4   Baltic languagues
iso8859_5                iso-8859-5, cyrillic     Bulgarian,
                                                  Byelorussian,
                                                  Macedonian, Russian,
                                                  Serbian
iso8859_6                iso-8859-6, arabic       Arabic
iso8859_7                iso-8859-7, greek,       Greek
                         greek8                   
iso8859_8                iso-8859-8, hebrew       Hebrew
iso8859_9                iso-8859-9, latin5, L5   Turkish
iso8859_10               iso-8859-10, latin6, L6  Nordic languages
iso8859_13               iso-8859-13              Baltic languages
iso8859_14               iso-8859-14, latin8, L8  Celtic languages
iso8859_15               iso-8859-15              Western Europe
koi8_r                                            Russian
koi8_u                                            Ukrainian
mac_cyrillic             maccyrillic              Bulgarian,
                                                  Byelorussian,
                                                  Macedonian, Russian,
                                                  Serbian
mac_greek                macgreek                 Greek
mac_iceland              maciceland               Icelandic
mac_latin2               maclatin2,               Central and Eastern
                         maccentraleurope         Europe
mac_roman                macroman                 Western Europe
mac_turkish              macturkish               Turkish
utf_16                   U16, utf16               all languages
utf_16_be                UTF-16BE                 all languages (BMP only)
utf_16_le                UTF-16LE                 all languages (BMP only)
utf_7                    U7                       all languages
utf_8                    U8, UTF, utf8            all languages

A number of codecs are specific to Python, so their codec names have no
meaning outside Python. Some of them don't convert from Unicode strings
to byte strings, but instead use the property of the Python codecs
machinery that any bijective function with one argument can be
considered as an encoding.

For the codecs listed below, the result in the "encoding" direction is
always a byte string. The result of the "decoding" direction is listed
as operand type in the table.

Codec              Aliases            Operand type       Purpose
------             ------             ------             ------
base64_codec       base64, base-64    byte string        Convert operand
                                                         to MIME base64
hex_codec          hex                byte string        Convert operand
                                                         to hexadecimal
                                                         representation,
                                                         with two digits
                                                         per byte
idna                                  Unicode string     Implements RFC
                                                         3490 . _Added in
                                                         Python version
                                                         2.3_ See also
                                                         `encodings.idna'
mbcs               dbcs               Unicode string     Windows only:
                                                         Encode operand
                                                         according to the
                                                         ANSI codepage
                                                         (CP_ACP)
palmos                                Unicode string     Encoding of
                                                         PalmOS 3.5
punycode                              Unicode string     Implements RFC
                                                         3492 . _Added in
                                                         Python version
                                                         2.3_
quopri_codec       quopri,            byte string        Convert operand
                   quoted-printable,                     to MIME quoted
                   quotedprintable                       printable
raw_unicode_escape                    Unicode string     Produce a string
                                                         that is suitable
                                                         as raw Unicode
                                                         literal in Python
                                                         source code
rot_13             rot13              byte string        Returns the
                                                         Caesar-cypher
                                                         encryption of the
                                                         operand
string_escape                         byte string        Produce a string
                                                         that is suitable
                                                         as string literal
                                                         in Python source
                                                         code
undefined                             any                Raise an
                                                         exception for all
                                                         conversion. Can
                                                         be used as the
                                                         system encoding
                                                         if no automatic
                                                         coercion between
                                                         byte and Unicode
                                                         strings is
                                                         desired.
unicode_escape                        Unicode string     Produce a string
                                                         that is suitable
                                                         as Unicode
                                                         literal in Python
                                                         source code
unicode_internal                      Unicode string     Return the
                                                         internal
                                                         represenation of
                                                         the operand
uu_codec           uu                 byte string        Convert the
                                                         operand using
                                                         uuencode
zlib_codec         zip, zlib          byte string        Compress the
                                                         operand using gzip


File: python-lib.info,  Node: encodingsidna --- Internationalized Domain Names in Applications,  Prev: Standard Encodings,  Up: codecs

`encodings.idna' -- Internationalized Domain Names in Applications
------------------------------------------------------------------

Internationalized Domain Names implementation

_Added in Python version 2.3_

This module implements RFC 3490 (Internationalized Domain Names in
Applications) and RFC 3492 (Nameprep: A Stringprep Profile for
Internationalized Domain Names (IDN)). It builds upon the `punycode'
encoding and `stringprep'.

These RFCs together define a protocol to support non-ASCII characters
in domain names. A domain name containing non-ASCII characters (such as
"www.Alliancefranc,aise.nu") is converted into an ASCII-compatible
encoding (ACE, such as "www.xn-alliancefranaise-npb.nu"). The ACE form
of the domain name is then used in all places where arbitrary
characters are not allowed by the protocol, such as DNS queries, HTTP
`Host' fields, and so on. This conversion is carried out in the
application; if possible invisible to the user: The application should
transparently convert Unicode domain labels to IDNA on the wire, and
convert back ACE labels to Unicode before presenting them to the user.

Python supports this conversion in several ways: The `idna' codec
allows to convert between Unicode and the ACE. Furthermore, the
`socket' module transparently converts Unicode host names to ACE, so
that applications need not be concerned about converting host names
themselves when they pass them to the socket module. On top of that,
modules that have host names as function parameters, such as `httplib'
and `ftplib', accept Unicode host names (`httplib' then also
transparently sends an IDNA hostname in the `Host' field if it sends
that field at all).

When receiving host names from the wire (such as in reverse name
lookup), no automatic conversion to Unicode is performed: Applications
wishing to present such host names to the user should decode them to
Unicode.

The module `encodings.idna' also implements the nameprep procedure,
which performs certain normalizations on host names, to achieve
case-insensitivity of international domain names, and to unify similar
characters. The nameprep functions can be used directly if desired.

`nameprep(label)'
     Return the nameprepped version of LABEL. The implementation
     currently assumes query strings, so `AllowUnassigned' is true.

`ToASCII(label)'
     Convert a label to ASCII, as specified in RFC 3490 .
     `UseSTD3ASCIIRules' is assumed to be false.

`ToUnicode(label)'
     Convert a label to Unicode, as specified in RFC 3490 .


File: python-lib.info,  Node: unicodedata,  Next: stringprep,  Prev: codecs,  Up: String Services

Unicode Database
================

Access the Unicode Database.

This module provides access to the Unicode Character Database which
defines character properties for all Unicode characters. The data in
this database is based on the `UnicodeData.txt' file version 3.2.0
which is publically available from <ftp://ftp.unicode.org/>.

The module uses the same names and symbols as defined by the
UnicodeData File Format 3.2.0 (see
<http://www.unicode.org/Public/UNIDATA/UnicodeData.html>).  It defines
the following functions:

`lookup(name)'
     Look up character by name.  If a character with the given name is
     found, return the corresponding Unicode character.  If not found,
     `KeyError' is raised.

`name(unichr[, default])'
     Returns the name assigned to the Unicode character UNICHR as a
     string. If no name is defined, DEFAULT is returned, or, if not
     given, `ValueError' is raised.

`decimal(unichr[, default])'
     Returns the decimal value assigned to the Unicode character UNICHR
     as integer. If no such value is defined, DEFAULT is returned, or,
     if not given, `ValueError' is raised.

`digit(unichr[, default])'
     Returns the digit value assigned to the Unicode character UNICHR
     as integer. If no such value is defined, DEFAULT is returned, or,
     if not given, `ValueError' is raised.

`numeric(unichr[, default])'
     Returns the numeric value assigned to the Unicode character UNICHR
     as float. If no such value is defined, DEFAULT is returned, or, if
     not given, `ValueError' is raised.

`category(unichr)'
     Returns the general category assigned to the Unicode character
     UNICHR as string.

`bidirectional(unichr)'
     Returns the bidirectional category assigned to the Unicode
     character UNICHR as string. If no such value is defined, an empty
     string is returned.

`combining(unichr)'
     Returns the canonical combining class assigned to the Unicode
     character UNICHR as integer. Returns `0' if no combining class is
     defined.

`mirrored(unichr)'
     Returns the mirrored property of assigned to the Unicode character
     UNICHR as integer. Returns `1' if the character has been
     identified as a "mirrored" character in bidirectional text, `0'
     otherwise.

`decomposition(unichr)'
     Returns the character decomposition mapping assigned to the Unicode
     character UNICHR as string. An empty string is returned in case no
     such mapping is defined.

`normalize(form, unistr)'
     Return the normal form FORM for the Unicode string UNISTR.  Valid
     values for FORM are 'NFC', 'NFKC', 'NFD', and 'NFKD'.

     The Unicode standard defines various normalization forms of a
     Unicode string, based on the definition of canonical equivalence
     and compatibility equivalence. In Unicode, several characters can
     be expressed in various way. For example, the character U+00C7
     (LATIN CAPITAL LETTER C WITH CEDILLA) can also be expressed as the
     sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING
     CEDILLA).

     For each character, there are two normal forms: normal form C and
     normal form D. Normal form D (NFD) is also known as canonical
     decomposition, and translates each character into its decomposed
     form.  Normal form C (NFC) first applies a canonical
     decomposition, then composes pre-combined characters again.

     In addition to these two forms, there two additional normal forms
     based on compatibility equivalence. In Unicode, certain characters
     are supported which normally would be unified with other
     characters. For example, U+2160 (ROMAN NUMERAL ONE) is really the
     same thing as U+0049 (LATIN CAPITAL LETTER I). However, it is
     supported in Unicode for compatibility with existing character
     sets (e.g. gb2312).

     The normal form KD (NFKD) will apply the compatibility
     decomposition, i.e. replace all compatibility characters with
     their equivalents. The normal form KC (NFKC) first applies the
     compatibility decomposition, followed by the canonical composition.

     _Added in Python version 2.3_

In addition, the module exposes the following constant:

`unidata_version'
     The version of the Unicode database used in this module.

     _Added in Python version 2.3_


File: python-lib.info,  Node: stringprep,  Prev: unicodedata,  Up: String Services

Internet String Preparation
===========================

String preparation, as per RFC 3453

When identifying things (such as host names) in the internet, it is
often necessary to compare such identifications for "equality". Exactly
how this comparison is executed may depend on the application domain,
e.g. whether it should be case-insensitive or not. It may be also
necessary to restrict the possible identifications, to allow only
identifications consisting of "printable" characters.

RFC 3454 defines a procedure for "preparing" Unicode strings in
internet protocols. Before passing strings onto the wire, they are
processed with the preparation procedure, after which they have a
certain normalized form. The RFC defines a set of tables, which can be
combined into profiles. Each profile must define which tables it uses,
and what other optional parts of the `stringprep' procedure are part of
the profile. One example of a `stringprep' profile is `nameprep', which
is used for internationalized domain names.

The module `stringprep' only exposes the tables from RFC 3454. As these
tables would be very large to represent them as dictionaries or lists,
the module uses the Unicode character database internally. The module
source code itself was generated using the `mkstringprep.py' utility.

As a result, these tables are exposed as functions, not as data
structures. There are two kinds of tables in the RFC: sets and
mappings. For a set, `stringprep' provides the "characteristic
function", i.e. a function that returns true if the parameter is part
of the set. For mappings, it provides the mapping function: given the
key, it returns the associated value. Below is a list of all functions
available in the module.

`in_table_a1(code)'
     Determine whether CODE is in table{A.1} (Unassigned code points in
     Unicode 3.2).

`in_table_b1(code)'
     Determine whether CODE is in table{B.1} (Commonly mapped to
     nothing).

`map_table_b2(code)'
     Return the mapped value for CODE according to table{B.2} (Mapping
     for case-folding used with NFKC).

`map_table_b3(code)'
     Return the mapped value for CODE according to table{B.3} (Mapping
     for case-folding used with no normalization).

`in_table_c11(code)'
     Determine whether CODE is in table{C.1.1} (ASCII space characters).

`in_table_c12(code)'
     Determine whether CODE is in table{C.1.2} (Non-ASCII space
     characters).

`in_table_c11_c12(code)'
     Determine whether CODE is in table{C.1} (Space characters, union
     of C.1.1 and C.1.2).

`in_table_c21(code)'
     Determine whether CODE is in table{C.2.1} (ASCII control
     characters).

`in_table_c22(code)'
     Determine whether CODE is in table{C.2.2} (Non-ASCII control
     characters).

`in_table_c21_c22(code)'
     Determine whether CODE is in table{C.2} (Control characters, union
     of C.2.1 and C.2.2).

`in_table_c3(code)'
     Determine whether CODE is in table{C.3} (Private use).

`in_table_c4(code)'
     Determine whether CODE is in table{C.4} (Non-character code
     points).

`in_table_c5(code)'
     Determine whether CODE is in table{C.5} (Surrogate codes).

`in_table_c6(code)'
     Determine whether CODE is in table{C.6} (Inappropriate for plain
     text).

`in_table_c7(code)'
     Determine whether CODE is in table{C.7} (Inappropriate for
     canonical representation).

`in_table_c8(code)'
     Determine whether CODE is in table{C.8} (Change display properties
     or are deprecated).

`in_table_c9(code)'
     Determine whether CODE is in table{C.9} (Tagging characters).

`in_table_d1(code)'
     Determine whether CODE is in table{D.1} (Characters with
     bidirectional property "R" or "AL").

`in_table_d2(code)'
     Determine whether CODE is in table{D.2} (Characters with
     bidirectional property "L").


File: python-lib.info,  Node: Miscellaneous Services,  Next: Generic Operating System Services,  Prev: String Services,  Up: Top

Miscellaneous Services
**********************

The modules described in this chapter provide miscellaneous services
that are available in all Python versions.  Here's an overview:

* Menu:

* pydoc::
* doctest::
* unittest::
* test::
* testtest_support::
* math::
* cmath::
* random::
* whrandom::
* bisect::
* heapq::
* array::
* sets::
* itertools::
* ConfigParser::
* fileinput::
* xreadlines::
* calendar::
* cmd::
* shlex::


File: python-lib.info,  Node: pydoc,  Next: doctest,  Prev: Miscellaneous Services,  Up: Miscellaneous Services

Documentation generator and online help system
==============================================

Documentation generator and online help system.

_Added in Python version 2.1_

The `pydoc' module automatically generates documentation from Python
modules.  The documentation can be presented as pages of text on the
console, served to a Web browser, or saved to HTML files.

The built-in function `help()' invokes the online help system in the
interactive interpreter, which uses `pydoc' to generate its
documentation as text on the console.  The same text documentation can
also be viewed from outside the Python interpreter by running `pydoc'
as a script at the operating system's command prompt.  For example,
running

     pydoc sys

at a shell prompt will display documentation on the `sys' module, in a
style similar to the manual pages shown by the UNIX `man' command.  The
argument to `pydoc' can be the name of a function, module, or package,
or a dotted reference to a class, method, or function within a module
or module in a package.  If the argument to `pydoc' looks like a path
(that is, it contains the path separator for your operating system,
such as a slash in UNIX), and refers to an existing Python source file,
then documentation is produced for that file.

Specifying a `-w' flag before the argument will cause HTML
documentation to be written out to a file in the current directory,
instead of displaying text on the console.

Specifying a `-k' flag before the argument will search the synopsis
lines of all available modules for the keyword given as the argument,
again in a manner similar to the UNIX `man' command.  The synopsis line
of a module is the first line of its documentation string.

You can also use `pydoc' to start an HTTP server on the local machine
that will serve documentation to visiting Web browsers.  `pydoc' `-p
1234' will start a HTTP server on port 1234, allowing you to browse the
documentation at `http://localhost:1234/' in your preferred Web browser.
`pydoc' `-g' will start the server and additionally bring up a small
`Tkinter'-based graphical interface to help you search for
documentation pages.

When `pydoc' generates documentation, it uses the current environment
and path to locate modules.  Thus, invoking `pydoc' `spam' documents
precisely the version of the module you would get if you started the
Python interpreter and typed `import spam'.


File: python-lib.info,  Node: doctest,  Next: unittest,  Prev: pydoc,  Up: Miscellaneous Services

Test docstrings represent reality
=================================

A framework for verifying examples in docstrings.

The `doctest' module searches a module's docstrings for text that looks
like an interactive Python session, then executes all such sessions to
verify they still work exactly as shown.  Here's a complete but small
example:

     """
     This is module example.
     
     Example supplies one function, factorial.  For example,
     
     >>> factorial(5)
     120
     """
     
     def factorial(n):
         """Return the factorial of n, an exact integer >= 0.
     
         If the result is small enough to fit in an int, return an int.
         Else return a long.
     
         >>> [factorial(n) for n in range(6)]
         [1, 1, 2, 6, 24, 120]
         >>> [factorial(long(n)) for n in range(6)]
         [1, 1, 2, 6, 24, 120]
         >>> factorial(30)
         265252859812191058636308480000000L
         >>> factorial(30L)
         265252859812191058636308480000000L
         >>> factorial(-1)
         Traceback (most recent call last):
             ...
         ValueError: n must be >= 0
     
         Factorials of floats are OK, but the float must be an exact integer:
         >>> factorial(30.1)
         Traceback (most recent call last):
             ...
         ValueError: n must be exact integer
         >>> factorial(30.0)
         265252859812191058636308480000000L
     
         It must also not be ridiculously large:
         >>> factorial(1e100)
         Traceback (most recent call last):
             ...
         OverflowError: n too large
         """


         import math
         if not n >= 0:
             raise ValueError("n must be >= 0")
         if math.floor(n) != n:
             raise ValueError("n must be exact integer")
         if n+1 == n:  # catch a value like 1e300
             raise OverflowError("n too large")
         result = 1
         factor = 2
         while factor <= n:
             try:
                 result *= factor
             except OverflowError:
                 result *= long(factor)
             factor += 1
         return result
     
     def _test():
         import doctest, example
         return doctest.testmod(example)
     
     if __name__ == "__main__":
         _test()

If you run `example.py' directly from the command line, `doctest' works
its magic:

     $ python example.py
     $

There's no output!  That's normal, and it means all the examples
worked.  Pass `-v' to the script, and `doctest' prints a detailed log
of what it's trying, and prints a summary at the end:

     $ python example.py -v
     Running example.__doc__
     Trying: factorial(5)
     Expecting: 120
     ok
     0 of 1 examples failed in example.__doc__
     Running example.factorial.__doc__
     Trying: [factorial(n) for n in range(6)]
     Expecting: [1, 1, 2, 6, 24, 120]
     ok
     Trying: [factorial(long(n)) for n in range(6)]
     Expecting: [1, 1, 2, 6, 24, 120]
     ok
     Trying: factorial(30)
     Expecting: 265252859812191058636308480000000L
     ok

And so on, eventually ending with:

     Trying: factorial(1e100)
     Expecting:
     Traceback (most recent call last):
         ...
     OverflowError: n too large
     ok
     0 of 8 examples failed in example.factorial.__doc__
     2 items passed all tests:
        1 tests in example
        8 tests in example.factorial
     9 tests in 2 items.
     9 passed and 0 failed.
     Test passed.
     $

That's all you need to know to start making productive use of
`doctest'!  Jump in.  The docstrings in `doctest.py' contain detailed
information about all aspects of `doctest', and we'll just cover the
more important points here.

* Menu:

* Normal Usage::
* Which Docstrings Are Examined?::
* What's the Execution Context?::
* What About Exceptions?::
* Advanced Usage::
* How are Docstring Examples Recognized?::
* Warnings::
* Soapbox::


File: python-lib.info,  Node: Normal Usage,  Next: Which Docstrings Are Examined?,  Prev: doctest,  Up: doctest

Normal Usage
------------

In normal use, end each module `M' with:

     def _test():
         import doctest, M           # replace M with your module's name
         return doctest.testmod(M)   # ditto
     
     if __name__ == "__main__":
         _test()

If you want to test the module as the main module, you don't need to
pass M to `testmod()'; in this case, it will test the current module.

Then running the module as a script causes the examples in the
docstrings to get executed and verified:

     python M.py

This won't display anything unless an example fails, in which case the
failing example(s) and the cause(s) of the failure(s) are printed to
stdout, and the final line of output is `'Test failed.''.

Run it with the `-v' switch instead:

     python M.py -v

and a detailed report of all examples tried is printed to standard
output, along with assorted summaries at the end.

You can force verbose mode by passing `verbose=1' to `testmod()', or
prohibit it by passing `verbose=0'.  In either of those cases,
`sys.argv' is not examined by `testmod()'.

In any case, `testmod()' returns a 2-tuple of ints `(F, T)', where F is
the number of docstring examples that failed and T is the total number
of docstring examples attempted.


File: python-lib.info,  Node: Which Docstrings Are Examined?,  Next: What's the Execution Context?,  Prev: Normal Usage,  Up: doctest

Which Docstrings Are Examined?
------------------------------

See the docstrings in `doctest.py' for all the details.  They're
unsurprising: the module docstring, and all function, class and method
docstrings are searched.  Optionally, the tester can be directed to
exclude docstrings attached to objects with private names.  Objects
imported into the module are not searched.

In addition, if `M.__test__' exists and "is true", it must be a dict,
and each entry maps a (string) name to a function object, class object,
or string.  Function and class object docstrings found from
`M.__test__' are searched even if the tester has been directed to skip
over private names in the rest of the module.  In output, a key `K' in
`M.__test__' appears with name

     <name of M>.__test__.K

Any classes found are recursively searched similarly, to test
docstrings in their contained methods and nested classes.  While
private names reached from `M''s globals can be optionally skipped, all
names reached from `M.__test__' are searched.


File: python-lib.info,  Node: What's the Execution Context?,  Next: What About Exceptions?,  Prev: Which Docstrings Are Examined?,  Up: doctest

What's the Execution Context?
-----------------------------

By default, each time `testmod()' finds a docstring to test, it uses a
_copy_ of `M''s globals, so that running tests on a module doesn't
change the module's real globals, and so that one test in `M' can't
leave behind crumbs that accidentally allow another test to work.  This
means examples can freely use any names defined at top-level in `M',
and names defined earlier in the docstring being run.

You can force use of your own dict as the execution context by passing
`globs=your_dict' to `testmod()' instead.  Presumably this would be a
copy of `M.__dict__' merged with the globals from other imported
modules.


File: python-lib.info,  Node: What About Exceptions?,  Next: Advanced Usage,  Prev: What's the Execution Context?,  Up: doctest

What About Exceptions?
----------------------

No problem, as long as the only output generated by the example is the
traceback itself.  For example:

     >>> [1, 2, 3].remove(42)
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     ValueError: list.remove(x): x not in list
     >>>

Note that only the exception type and value are compared (specifically,
only the last line in the traceback).  The various "File" lines in
between can be left out (unless they add significantly to the
documentation value of the example).


File: python-lib.info,  Node: Advanced Usage,  Next: How are Docstring Examples Recognized?,  Prev: What About Exceptions?,  Up: doctest

Advanced Usage
--------------

Several module level functions are available for controlling how
doctests are run.

`debug(module, name)'
     Debug a single docstring containing doctests.

     Provide the MODULE (or dotted name of the module) containing the
     docstring to be debugged and the NAME (within the module) of the
     object with the docstring to be debugged.

     The doctest examples are extracted (see function `testsource()'),
     and written to a temporary file.  The Python debugger, `pdb', is
     then invoked on that file.  _Added in Python version 2.3_

`testmod()'
     This function provides the most basic interface to the doctests.
     It creates a local instance of class `Tester', runs appropriate
     methods of that class, and merges the results into the global
     `Tester' instance, `master'.

     To get finer control than `testmod()' offers, create an instance
     of `Tester' with custom policies, or run methods of `master'
     directly.  See `Tester.__doc__' for details.

`testsource(module, name)'
     Extract the doctest examples from a docstring.

     Provide the MODULE (or dotted name of the module) containing the
     tests to be extracted and the NAME (within the module) of the
     object with the docstring containing the tests to be extracted.

     The doctest examples are returned as a string containing Python
     code.  The expected output blocks in the examples are converted to
     Python comments.  _Added in Python version 2.3_

`DocTestSuite([module])'
     Convert doctest tests for a module to a ``unittest'.TestSuite'.

     The returned `TestSuite' is to be run by the unittest framework
     and runs each doctest in the module.  If any of the doctests fail,
     then the synthesized unit test fails, and a `DocTestTestFailure'
     exception is raised showing the name of the file containing the
     test and a (sometimes approximate) line number.

     The optional MODULE argument provides the module to be tested.  It
     can be a module object or a (possibly dotted) module name.  If not
     specified, the module calling this function is used.

     Example using one of the many ways that the `unittest' module can
     use a `TestSuite':

              import unittest
              import doctest
              import my_module_with_doctests
          
              suite = doctest.DocTestSuite(my_module_with_doctests)
              runner = unittest.TextTestRunner()
              runner.run(suite)

     _Added in Python version 2.3_ _This function does not currently
     search `M.__test__' and its search technique does not exactly
     match `testmod()' in every detail.  Future versions will bring the
     two into convergence._

