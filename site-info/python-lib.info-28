This is python-lib.info, produced by makeinfo version 4.3 from
python-lib.texi.

October 3, 2003


File: python-lib.info,  Node: Instant Users Manual,  Next: Deterministic Profiling,  Prev: Profiler Changes,  Up: Python Profiler

Instant Users Manual
====================

This section is provided for users that "don't want to read the
manual." It provides a very brief overview, and allows a user to
rapidly perform profiling on an existing application.

To profile an application with a main entry point of `foo()', you would
add the following to your module:

     import profile
     profile.run('foo()')

The above action would cause `foo()' to be run, and a series of
informative lines (the profile) to be printed.  The above approach is
most useful when working with the interpreter.  If you would like to
save the results of a profile into a file for later examination, you
can supply a file name as the second argument to the `run()' function:

     import profile
     profile.run('foo()', 'fooprof')

The file `profile.py' can also be invoked as a script to profile
another script.  For example:

     python /usr/local/lib/python1.5/profile.py myscript.py

When you wish to review the profile, you should use the methods in the
`pstats' module.  Typically you would load the statistics data as
follows:

     import pstats
     p = pstats.Stats('fooprof')

The class `Stats' (the above code just created an instance of this
class) has a variety of methods for manipulating and printing the data
that was just read into `p'.  When you ran `profile.run()' above, what
was printed was the result of three method calls:

     p.strip_dirs().sort_stats(-1).print_stats()

The first method removed the extraneous path from all the module names.
The second method sorted all the entries according to the standard
module/line/name string that is printed (this is to comply with the
semantics of the old profiler).  The third method printed out all the
statistics.  You might try the following sort calls:

     p.sort_stats('name')
     p.print_stats()

The first call will actually sort the list by function name, and the
second call will print out the statistics.  The following are some
interesting calls to experiment with:

     p.sort_stats('cumulative').print_stats(10)

This sorts the profile by cumulative time in a function, and then only
prints the ten most significant lines.  If you want to understand what
algorithms are taking time, the above line is what you would use.

If you were looking to see what functions were looping a lot, and
taking a lot of time, you would do:

     p.sort_stats('time').print_stats(10)

to sort according to time spent within each function, and then print
the statistics for the top ten functions.

You might also try:

     p.sort_stats('file').print_stats('__init__')

This will sort all the statistics by file name, and then print out
statistics for only the class init methods ('cause they are spelled
with `__init__' in them).  As one final example, you could try:

     p.sort_stats('time', 'cum').print_stats(.5, 'init')

This line sorts statistics with a primary key of time, and a secondary
key of cumulative time, and then prints out some of the statistics.  To
be specific, the list is first culled down to 50% (re: `.5') of its
original size, then only lines containing `init' are maintained, and
that sub-sub-list is printed.

If you wondered what functions called the above functions, you could
now (`p' is still sorted according to the last criteria) do:

     p.print_callers(.5, 'init')

and you would get a list of callers for each of the listed functions.

If you want more functionality, you're going to have to read the
manual, or guess what the following functions do:

     p.print_callees()
     p.add('fooprof')

Invoked as a script, the `pstats' module is a statistics browser for
reading and examining profile dumps.  It has a simple line-oriented
interface (implemented using `cmd') and interactive help.


File: python-lib.info,  Node: Deterministic Profiling,  Next: Reference Manual,  Prev: Instant Users Manual,  Up: Python Profiler

What Is Deterministic Profiling?
================================

"Deterministic profiling" is meant to reflect the fact that all
_function call_, _function return_, and _exception_ events are
monitored, and precise timings are made for the intervals between these
events (during which time the user's code is executing).  In contrast,
"statistical profiling" (which is not done by this module) randomly
samples the effective instruction pointer, and deduces where time is
being spent.  The latter technique traditionally involves less overhead
(as the code does not need to be instrumented), but provides only
relative indications of where time is being spent.

In Python, since there is an interpreter active during execution, the
presence of instrumented code is not required to do deterministic
profiling.  Python automatically provides a "hook" (optional callback)
for each event.  In addition, the interpreted nature of Python tends to
add so much overhead to execution, that deterministic profiling tends
to only add small processing overhead in typical applications.  The
result is that deterministic profiling is not that expensive, yet
provides extensive run time statistics about the execution of a Python
program.

Call count statistics can be used to identify bugs in code (surprising
counts), and to identify possible inline-expansion points (high call
counts).  Internal time statistics can be used to identify "hot loops"
that should be carefully optimized.  Cumulative time statistics should
be used to identify high level errors in the selection of algorithms.
Note that the unusual handling of cumulative times in this profiler
allows statistics for recursive implementations of algorithms to be
directly compared to iterative implementations.


File: python-lib.info,  Node: Reference Manual,  Next: Limitations,  Prev: Deterministic Profiling,  Up: Python Profiler

Reference Manual
================

Python profiler

The primary entry point for the profiler is the global function
`profile.run()'.  It is typically used to create any profile
information.  The reports are formatted and printed using methods of
the class `pstats.Stats'.  The following is a description of all of
these standard entry points and functions.  For a more in-depth view of
some of the code, consider reading the later section on Profiler
Extensions, which includes discussion of how to derive "better"
profilers from the classes presented, or reading the source code for
these modules.

`run(string[, filename[, ...]])'
     This function takes a single argument that has can be passed to the
     `exec' statement, and an optional file name.  In all cases this
     routine attempts to `exec' its first argument, and gather profiling
     statistics from the execution. If no file name is present, then
     this function automatically prints a simple profiling report,
     sorted by the standard name string (file/line/function-name) that
     is presented in each line.  The following is a typical output from
     such a call:

                main()
                2706 function calls (2004 primitive calls) in 4.504 CPU seconds
          
          Ordered by: standard name
          
          ncalls  tottime  percall  cumtime  percall filename:lineno(function)
               2    0.006    0.003    0.953    0.477 pobject.py:75(save_objects)
            43/3    0.533    0.012    0.749    0.250 pobject.py:99(evaluate)
           ...

     The first line indicates that this profile was generated by the
     call:\ `profile.run('main()')', and hence the exec'ed string is
     `'main()''.  The second line indicates that 2706 calls were
     monitored.  Of those calls, 2004 were "primitive".  We define
     "primitive" to mean that the call was not induced via recursion.
     The next line: `Ordered by: standard name', indicates that the
     text string in the far right column was used to sort the output.
     The column headings include:

    `ncalls'
          for the number of calls,

    `tottime'
          for the total time spent in the given function (and excluding
          time made in calls to sub-functions),

    `percall'
          is the quotient of `tottime' divided by `ncalls'

    `cumtime'
          is the total time spent in this and all subfunctions (from
          invocation till exit). This figure is accurate _even_ for
          recursive functions.

    `percall'
          is the quotient of `cumtime' divided by primitive calls

    `filename:lineno(function)'
          provides the respective data of each function

     When there are two numbers in the first column (for example,
     `43/3'), then the latter is the number of primitive calls, and the
     former is the actual number of calls.  Note that when the function
     does not recurse, these two values are the same, and only the
     single figure is printed.

Analysis of the profiler data is done using this class from the
`pstats' module:

`Stats(filename[, ...])'
     This class constructor creates an instance of a "statistics object"
     from a FILENAME (or set of filenames).  `Stats' objects are
     manipulated by methods, in order to print useful reports.

     The file selected by the above constructor must have been created
     by the corresponding version of `profile'.  To be specific, there
     is _no_ file compatibility guaranteed with future versions of this
     profiler, and there is no compatibility with files produced by
     other profilers (such as the old system profiler).

     If several files are provided, all the statistics for identical
     functions will be coalesced, so that an overall view of several
     processes can be considered in a single report.  If additional
     files need to be combined with data in an existing `Stats' object,
     the `add()' method can be used.

* Menu:

* Stats Class::


File: python-lib.info,  Node: Stats Class,  Prev: Reference Manual,  Up: Reference Manual

The `Stats' Class
-----------------

`Stats' objects have the following methods:

`strip_dirs()'
     This method for the `Stats' class removes all leading path
     information from file names.  It is very useful in reducing the
     size of the printout to fit within (close to) 80 columns.  This
     method modifies the object, and the stripped information is lost.
     After performing a strip operation, the object is considered to
     have its entries in a "random" order, as it was just after object
     initialization and loading.  If `strip_dirs()' causes two function
     names to be indistinguishable (they are on the same line of the
     same filename, and have the same function name), then the
     statistics for these two entries are accumulated into a single
     entry.

`add(filename[, ...])'
     This method of the `Stats' class accumulates additional profiling
     information into the current profiling object.  Its arguments
     should refer to filenames created by the corresponding version of
     `profile.run()'.  Statistics for identically named (re: file,
     line, name) functions are automatically accumulated into single
     function statistics.

`dump_stats(filename)'
     Save the data loaded into the `Stats' object to a file named
     FILENAME.  The file is created if it does not exist, and is
     overwritten if it already exists.  This is equivalent to the
     method of the same name on the `profile.Profile' class.  _Added in
     Python version 2.3_

`sort_stats(key[, ...])'
     This method modifies the `Stats' object by sorting it according to
     the supplied criteria.  The argument is typically a string
     identifying the basis of a sort (example: `'time'' or `'name'').

     When more than one key is provided, then additional keys are used
     as secondary criteria when the there is equality in all keys
     selected before them.  For example, `sort_stats('name', 'file')'
     will sort all the entries according to their function name, and
     resolve all ties (identical function names) by sorting by file
     name.

     Abbreviations can be used for any key names, as long as the
     abbreviation is unambiguous.  The following are the keys currently
     defined:

     Valid Arg                          Meaning
     ------                             -----
     'calls'                            call count
     'cumulative'                       cumulative time
     'file'                             file name
     'module'                           file name
     'pcalls'                           primitive call count
     'line'                             line number
     'name'                             function name
     'nfl'                              name/file/line
     'stdname'                          standard name
     'time'                             internal time

     Note that all sorts on statistics are in descending order (placing
     most time consuming items first), where as name, file, and line
     number searches are in ascending order (alphabetical). The subtle
     distinction between `'nfl'' and `'stdname'' is that the standard
     name is a sort of the name as printed, which means that the
     embedded line numbers get compared in an odd way.  For example,
     lines 3, 20, and 40 would (if the file names were the same) appear
     in the string order 20, 3 and 40.  In contrast, `'nfl'' does a
     numeric compare of the line numbers.  In fact, `sort_stats('nfl')'
     is the same as `sort_stats('name', 'file', 'line')'.

     For compatibility with the old profiler, the numeric arguments
     `-1', `0', `1', and `2' are permitted.  They are interpreted as
     `'stdname'', `'calls'', `'time'', and `'cumulative'' respectively.
     If this old style format (numeric) is used, only one sort key
     (the numeric key) will be used, and additional arguments will be
     silently ignored.

`reverse_order()'
     This method for the `Stats' class reverses the ordering of the
     basic list within the object.  This method is provided primarily
     for compatibility with the old profiler.  Its utility is
     questionable now that ascending vs descending order is properly
     selected based on the sort key of choice.

`print_stats([restriction, ...])'
     This method for the `Stats' class prints out a report as described
     in the `profile.run()' definition.

     The order of the printing is based on the last `sort_stats()'
     operation done on the object (subject to caveats in `add()' and
     `strip_dirs()').

     The arguments provided (if any) can be used to limit the list down
     to the significant entries.  Initially, the list is taken to be the
     complete set of profiled functions.  Each restriction is either an
     integer (to select a count of lines), or a decimal fraction between
     0.0 and 1.0 inclusive (to select a percentage of lines), or a
     regular expression (to pattern match the standard name that is
     printed; as of Python 1.5b1, this uses the Perl-style regular
     expression syntax defined by the `re' module).  If several
     restrictions are provided, then they are applied sequentially.
     For example:

          print_stats(.1, 'foo:')

     would first limit the printing to first 10% of list, and then only
     print functions that were part of filename `.*foo:'.  In contrast,
     the command:

          print_stats('foo:', .1)

     would limit the list to all functions having file names `.*foo:',
     and then proceed to only print the first 10% of them.

`print_callers([restriction, ...])'
     This method for the `Stats' class prints a list of all functions
     that called each function in the profiled database.  The ordering
     is identical to that provided by `print_stats()', and the
     definition of the restricting argument is also identical.  For
     convenience, a number is shown in parentheses after each caller to
     show how many times this specific call was made.  A second
     non-parenthesized number is the cumulative time spent in the
     function at the right.

`print_callees([restriction, ...])'
     This method for the `Stats' class prints a list of all function
     that were called by the indicated function.  Aside from this
     reversal of direction of calls (re: called vs was called by), the
     arguments and ordering are identical to the `print_callers()'
     method.

`ignore()'
     _This is deprecated in Python 1.5.1.  This is not needed in modern
     versions of Python.(1)_

---------- Footnotes ----------

(1)  This was once necessary, when Python would print any unused
expression result that was not `None'.  The method is still defined for
backward compatibility.


File: python-lib.info,  Node: Limitations,  Next: Calibration,  Prev: Reference Manual,  Up: Python Profiler

Limitations
===========

There are two fundamental limitations on this profiler.  The first is
that it relies on the Python interpreter to dispatch "call", "return",
and "exception" events.  Compiled C code does not get interpreted, and
hence is "invisible" to the profiler.  All time spent in C code
(including built-in functions) will be charged to the Python function
that invoked the C code.  If the C code calls out to some native Python
code, then those calls will be profiled properly.

The second limitation has to do with accuracy of timing information.
There is a fundamental problem with deterministic profilers involving
accuracy.  The most obvious restriction is that the underlying "clock"
is only ticking at a rate (typically) of about .001 seconds.  Hence no
measurements will be more accurate than the underlying clock.  If
enough measurements are taken, then the "error" will tend to average
out. Unfortunately, removing this first error induces a second source
of error...

The second problem is that it "takes a while" from when an event is
dispatched until the profiler's call to get the time actually _gets_
the state of the clock.  Similarly, there is a certain lag when exiting
the profiler event handler from the time that the clock's value was
obtained (and then squirreled away), until the user's code is once
again executing.  As a result, functions that are called many times, or
call many functions, will typically accumulate this error.  The error
that accumulates in this fashion is typically less than the accuracy of
the clock (less than one clock tick), but it _can_ accumulate and
become very significant.  This profiler provides a means of calibrating
itself for a given platform so that this error can be probabilistically
(on the average) removed.  After the profiler is calibrated, it will be
more accurate (in a least square sense), but it will sometimes produce
negative numbers (when call counts are exceptionally low, and the gods
of probability work against you :-). )  Do _not_ be alarmed by negative
numbers in the profile.  They should _only_ appear if you have
calibrated your profiler, and the results are actually better than
without calibration.


File: python-lib.info,  Node: Calibration,  Next: Profiler Extensions,  Prev: Limitations,  Up: Python Profiler

Calibration
===========

The profiler subtracts a constant from each event handling time to
compensate for the overhead of calling the time function, and socking
away the results.  By default, the constant is 0.  The following
procedure can be used to obtain a better constant for a given platform
(see discussion in section Limitations above).

     import profile
     pr = profile.Profile()
     for i in range(5):
         print pr.calibrate(10000)

The method executes the number of Python calls given by the argument,
directly and again under the profiler, measuring the time for both.  It
then computes the hidden overhead per profiler event, and returns that
as a float.  For example, on an 800 MHz Pentium running Windows 2000,
and using Python's time.clock() as the timer, the magical number is
about 12.5e-6.

The object of this exercise is to get a fairly consistent result.  If
your computer is _very_ fast, or your timer function has poor
resolution, you might have to pass 100000, or even 1000000, to get
consistent results.

When you have a consistent answer, there are three ways you can use
it:(1)

     import profile
     
     # 1. Apply computed bias to all Profile instances created hereafter.
     profile.Profile.bias = your_computed_bias
     
     # 2. Apply computed bias to a specific Profile instance.
     pr = profile.Profile()
     pr.bias = your_computed_bias
     
     # 3. Specify computed bias in instance constructor.
     pr = profile.Profile(bias=your_computed_bias)

If you have a choice, you are better off choosing a smaller constant,
and then your results will "less often" show up as negative in profile
statistics.

---------- Footnotes ----------

(1) Prior to Python 2.2, it was necessary to edit the profiler source
code to embed the bias as a literal number.  You still can, but that
method is no longer described, because no longer needed.


File: python-lib.info,  Node: Profiler Extensions,  Next: hotshot,  Prev: Calibration,  Up: Python Profiler

Deriving Better Profilers
=========================

The `Profile' class of module `profile' was written so that derived
classes could be developed to extend the profiler.  The details are not
described here, as doing this successfully requires an expert
understanding of how the `Profile' class works internally.  Study the
source code of module `profile' carefully if you want to pursue this.

If all you want to do is change how current time is determined (for
example, to force use of wall-clock time or elapsed process time), pass
the timing function you want to the `Profile' class constructor:

     pr = profile.Profile(your_time_func)

The resulting profiler will then call `your_time_func()'.  The function
should return a single number, or a list of numbers whose sum is the
current time (like what `os.times()' returns).  If the function returns
a single time number, or the list of returned numbers has length 2,
then you will get an especially fast version of the dispatch routine.

Be warned that you should calibrate the profiler class for the timer
function that you choose.  For most machines, a timer that returns a
lone integer value will provide the best results in terms of low
overhead during profiling.  (`os.times()' is _pretty_ bad, as it
returns a tuple of floating point values).  If you want to substitute a
better timer in the cleanest fashion, derive a class and hardwire a
replacement dispatch method that best handles your timer call, along
with the appropriate calibration constant.


File: python-lib.info,  Node: hotshot,  Next: timeit,  Prev: Profiler Extensions,  Up: Python Profiler

High performance logging profiler
=================================

High performance logging profiler, mostly written in C.

_Added in Python version 2.2_

This module provides a nicer interface to the `_hotshot' C module.
Hotshot is a replacement for the existing `profile' module. As it's
written mostly in C, it should result in a much smaller performance
impact than the existing `profile' module.

`Profile(logfile[, lineevents`=0'[, linetimings`=1']])'
     The profiler object. The argument LOGFILE is the name of a log
     file to use for logged profile data. The argument LINEEVENTS
     specifies whether to generate events for every source line, or
     just on function call/return. It defaults to `0' (only log function
     call/return). The argument LINETIMINGS specifies whether to record
     timing information. It defaults to `1' (store timing information).

* Menu:

* Profile Objects::
* Using hotshot data::
* Example Usage::


File: python-lib.info,  Node: Profile Objects,  Next: Using hotshot data,  Prev: hotshot,  Up: hotshot

Profile Objects
---------------

Profile objects have the following methods:

`addinfo(key, value)'
     Add an arbitrary labelled value to the profile output.

`close()'
     Close the logfile and terminate the profiler.

`fileno()'
     Return the file descriptor of the profiler's log file.

`run(cmd)'
     Profile an `exec'-compatible string in the script environment.
     The globals from the `__main__' module are used as both the
     globals and locals for the script.

`runcall(func, *args, **keywords)'
     Profile a single call of a callable.  Additional positional and
     keyword arguments may be passed along; the result of the call is
     returned, and exceptions are allowed to propogate cleanly, while
     ensuring that profiling is disabled on the way out.

`runctx(cmd, globals, locals)'
     Evaluate an `exec'-compatible string in a specific environment.
     The string is compiled before profiling begins.

`start()'
     Start the profiler.

`stop()'
     Stop the profiler.


File: python-lib.info,  Node: Using hotshot data,  Next: Example Usage,  Prev: Profile Objects,  Up: hotshot

Using hotshot data
------------------

Statistical analysis for Hotshot

_Added in Python version 2.2_

This module loads hotshot profiling data into the standard `pstats'
Stats objects.

`load(filename)'
     Load hotshot data from FILENAME. Returns an instance of the
     `pstats.Stats' class.

See also:
     *Note Reference Manual:: The `profile' module's `Stats' class


File: python-lib.info,  Node: Example Usage,  Prev: Using hotshot data,  Up: hotshot

Example Usage
-------------

Note that this example runs the python "benchmark" pystones.  It can
take some time to run, and will produce large output files.

     >>> import hotshot, hotshot.stats, test.pystone
     >>> prof = hotshot.Profile("stones.prof")
     >>> benchtime, stones = prof.runcall(test.pystone.pystones)
     >>> prof.close()
     >>> stats = hotshot.stats.load("stones.prof")
     >>> stats.strip_dirs()
     >>> stats.sort_stats('time', 'calls')
     >>> stats.print_stats(20)
              850004 function calls in 10.090 CPU seconds
     
        Ordered by: internal time, call count
     
        ncalls  tottime  percall  cumtime  percall filename:lineno(function)
             1    3.295    3.295   10.090   10.090 pystone.py:79(Proc0)
        150000    1.315    0.000    1.315    0.000 pystone.py:203(Proc7)
         50000    1.313    0.000    1.463    0.000 pystone.py:229(Func2)
      .
      .
      .


File: python-lib.info,  Node: timeit,  Prev: hotshot,  Up: Python Profiler

Measure execution time of small code snippets
=============================================

Measure the execution time of small code snippets.

_Added in Python version 2.3_

This module provides a simple way to time small bits of Python code.
It has both command line as well as callable interfaces.  It avoids a
number of common traps for measuring execution times.  See also Tim
Peters' introduction to the "Algorithms" chapter in the , published by
O'Reilly.

The module defines the following public class:

`Timer([stmt=`'pass'' [, setup=`'pass'' [, timer=<timer function>]]])'
     Class for timing execution speed of small code snippets.

     The constructor takes a statement to be timed, an additional
     statement used for setup, and a timer function.  Both statements
     default to `'pass''; the timer function is platform-dependent (see
     the module doc string).  The statements may contain newlines, as
     long as they don't contain multi-line string literals.

     To measure the execution time of the first statement, use the
     `timeit()' method.  The `repeat()' method is a convenience to call
     `timeit()' multiple times and return a list of results.

`print_exc([file=`None'])'
     Helper to print a traceback from the timed code.

     Typical use:

              t = Timer(...)       # outside the try/except
              try:
                  t.timeit(...)    # or t.repeat(...)
              except:
                  t.print_exc()

     The advantage over the standard traceback is that source lines in
     the compiled template will be displayed.  The optional FILE
     argument directs where the traceback is sent; it defaults to
     `sys.stderr'.

`repeat([repeat`=3' [, number`=1000000']])'
     Call `timeit()' a few times.

     This is a convenience function that calls the `timeit()'
     repeatedly, returning a list of results.  The first argument
     specifies how many times to call `timeit()'.  The second argument
     specifies the NUMBER argument for `timeit()'.

     _Notice:_ It's tempting to calculate mean and standard deviation
     from the result vector and report these.  However, this is not
     very useful.  In a typical case, the lowest value gives a lower
     bound for how fast your machine can run the given code snippet;
     higher values in the result vector are typically not caused by
     variability in Python's speed, but by other processes interfering
     with your timing accuracy.  So the `min()' of the result is
     probably the only number you should be interested in.  After that,
     you should look at the entire vector and apply common sense rather
     than statistics.

`timeit([number`=1000000'])'
     Time NUMBER executions of the main statement.  This executes the
     setup statement once, and then returns the time it takes to
     execute the main statement a number of times, measured in seconds
     as a float.  The argument is the number of times through the loop,
     defaulting to one million.  The main statement, the setup
     statement and the timer function to be used are passed to the
     constructor.

* Menu:

* Command Line Interface::
* Examples 7::


File: python-lib.info,  Node: Command Line Interface,  Next: Examples 7,  Prev: timeit,  Up: timeit

Command Line Interface
----------------------

When called as a program from the command line, the following form is
used:

     python timeit.py [-n N] [-r N] [-s S] [-t] [-c] [-h] [statement ...]

where the following options are understood:

`-n N/`--number=N''
     how many times to execute 'statement'

`-r N/`--repeat=N''
     how many times to repeat the timer (default 3)

`-s S/`--setup=S''
     statement to be executed once initially (default `'pass'')

`-t/`--time''
     use `time.time()' (default on all platforms but Windows)

`-c/`--clock''
     use `time.clock()' (default on Windows)

`-v/`--verbose''
     print raw timing results; repeat for more digits precision

`-h/`--help''
     print a short usage message and exit

A multi-line statement may be given by specifying each line as a
separate statement argument; indented lines are possible by enclosing
an argument in quotes and using leading spaces.  Multiple `-s' options
are treated similarly.

If `-n' is not given, a suitable number of loops is calculated by
trying successive powers of 10 until the total time is at least 0.2
seconds.

The default timer function is platform dependent.  On Windows,
`time.clock()' has microsecond granularity but `time.time()''s
granularity is 1/60th of a second; on UNIX, `time.clock()' has 1/100th
of a second granularity and `time.time()' is much more precise.  On
either platform, the default timer functions measure wall clock time,
not the CPU time.  This means that other processes running on the same
computer may interfere with the timing.  The best thing to do when
accurate timing is necessary is to repeat the timing a few times and
use the best time.  The `-r' option is good for this; the default of 3
repetitions is probably enough in most cases.  On UNIX, you can use
`time.clock()' to measure CPU time.

_Notice:_ There is a certain baseline overhead associated with
executing a pass statement.  The code here doesn't try to hide it, but
you should be aware of it.  The baseline overhead can be measured by
invoking the program without arguments.

The baseline overhead differs between Python versions!  Also, to fairly
compare older Python versions to Python 2.3, you may want to use
Python's `-O' option for the older versions to avoid timing
`SET_LINENO' instructions.


File: python-lib.info,  Node: Examples 7,  Prev: Command Line Interface,  Up: timeit

Examples
--------

Here are two example sessions (one using the command line, one using
the module interface) that compare the cost of using `hasattr()' vs.
`try'/`except' to test for missing and present object attributes.

     % timeit.py 'try:' '  str.__nonzero__' 'except AttributeError:' '  pass'
     100000 loops, best of 3: 15.7 usec per loop
     % timeit.py 'if hasattr(str, "__nonzero__"): pass'
     100000 loops, best of 3: 4.26 usec per loop
     % timeit.py 'try:' '  int.__nonzero__' 'except AttributeError:' '  pass'
     1000000 loops, best of 3: 1.43 usec per loop
     % timeit.py 'if hasattr(int, "__nonzero__"): pass'
     100000 loops, best of 3: 2.23 usec per loop

     >>> import timeit
     >>> s = """\
     ... try:
     ...     str.__nonzero__
     ... except AttributeError:
     ...     pass
     ... """
     >>> t = timeit.Timer(stmt=s)
     >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
     17.09 usec/pass
     >>> s = """\
     ... if hasattr(str, '__nonzero__'): pass
     ... """
     >>> t = timeit.Timer(stmt=s)
     >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
     4.85 usec/pass
     >>> s = """\
     ... try:
     ...     int.__nonzero__
     ... except AttributeError:
     ...     pass
     ... """
     >>> t = timeit.Timer(stmt=s)
     >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
     1.97 usec/pass
     >>> s = """\
     ... if hasattr(int, '__nonzero__'): pass
     ... """
     >>> t = timeit.Timer(stmt=s)
     >>> print "%.2f usec/pass" % (1000000 * t.timeit(number=100000)/100000)
     3.15 usec/pass

To give the `timeit' module access to functions you define, you can
pass a `setup' parameter which contains an import statement:

     def test():
         "Stupid test function"
         L = []
         for i in range(100):
             L.append(i)
     
     if __name__=='__main__':
         from timeit import Timer
         t = Timer("test()", "from __main__ import test")
         print t.timeit()


File: python-lib.info,  Node: Internet Protocols and Support,  Next: Internet Data Handling,  Prev: Python Profiler,  Up: Top

Internet Protocols and Support
******************************

The modules described in this chapter implement Internet protocols and
support for related technology.  They are all implemented in Python.
Most of these modules require the presence of the system-dependent
module `socket' , which is currently supported on most popular
platforms.  Here is an overview:

* Menu:

* webbrowser::
* cgi::
* cgitb::
* urllib::
* urllib2::
* httplib::
* ftplib::
* gopherlib::
* poplib::
* imaplib::
* nntplib::
* smtplib::
* telnetlib::
* urlparse::
* SocketServer::
* BaseHTTPServer::
* SimpleHTTPServer::
* CGIHTTPServer::
* Cookie::
* xmlrpclib::
* SimpleXMLRPCServer::
* DocXMLRPCServer::
* asyncore::
* asynchat::


File: python-lib.info,  Node: webbrowser,  Next: cgi,  Prev: Internet Protocols and Support,  Up: Internet Protocols and Support

Convenient Web-browser controller
=================================

Easy-to-use controller for Web browsers.

The `webbrowser' module provides a very high-level interface to allow
displaying Web-based documents to users.  The controller objects are
easy to use and are platform-independent.  Under most circumstances,
simply calling the `open()' function from this module will do the right
thing.

Under UNIX, graphical browsers are preferred under X11, but text-mode
browsers will be used if graphical browsers are not available or an X11
display isn't available.  If text-mode browsers are used, the calling
process will block until the user exits the browser.

Under UNIX, if the environment variable `BROWSER' exists, it is
interpreted to override the platform default list of browsers, as a
colon-separated list of browsers to try in order.  When the value of a
list part contains the string `%s', then it is interpreted as a literal
browser command line to be used with the argument URL substituted for
the `%s'; if the part does not contain `%s', it is simply interpreted
as the name of the browser to launch.

For non-UNIX platforms, or when X11 browsers are available on UNIX, the
controlling process will not wait for the user to finish with the
browser, but allow the browser to maintain its own window on the
display.

The following exception is defined:

`Error'
     Exception raised when a browser control error occurs.

The following functions are defined:

`open(url[, new=0][, autoraise=1])'
     Display URL using the default browser.  If NEW is true, a new
     browser window is opened if possible.  If AUTORAISE is true, the
     window is raised if possible (note that under many window managers
     this will occur regardless of the setting of this variable).

`open_new(url)'
     Open URL in a new window of the default browser, if possible,
     otherwise, open URL in the only browser window.

`get([name])'
     Return a controller object for the browser type NAME.  If NAME is
     empty, return a controller for a default browser appropriate to
     the caller's environment.

`register(name, constructor[, instance])'
     Register the browser type NAME.  Once a browser type is
     registered, the `get()' function can return a controller for that
     browser type.  If INSTANCE is not provided, or is `None',
     CONSTRUCTOR will be called without parameters to create an
     instance when needed.  If INSTANCE is provided, CONSTRUCTOR will
     never be called, and may be `None'.

     This entry point is only useful if you plan to either set the
     `BROWSER' variable or call `get' with a nonempty argument matching
     the name of a handler you declare.

A number of browser types are predefined.  This table gives the type
names that may be passed to the `get()' function and the corresponding
instantiations for the controller classes, all defined in this module.

Type Name                Class Name               Notes
------                   -----                    -----
'mozilla'                `Netscape('mozilla')'    
'netscape'               `Netscape('netscape')'   
'mosaic'                 `GenericBrowser('mosaic  
                         %s &')'                  
'kfm'                    `Konqueror()'            (1)
'grail'                  `Grail()'                
'links'                  `GenericBrowser('links   
                         %s')'                    
'lynx'                   `GenericBrowser('lynx    
                         %s')'                    
'w3m'                    `GenericBrowser('w3m     
                         %s')'                    
'windows-default'        `WindowsDefault'         (2)
'internet-config'        `InternetConfig'         (3)

Notes:

`(1)'
     "Konqueror" is the file manager for the KDE desktop environment for
     UNIX, and only makes sense to use if KDE is running.  Some way of
     reliably detecting KDE would be nice; the `KDEDIR' variable is not
     sufficient.  Note also that the name "kfm" is used even when using
     the `konqueror' command with KDE 2 -- the implementation selects
     the best strategy for running Konqueror.

`(2)'
     Only on Windows platforms; requires the common extension modules
     `win32api' and `win32con'.

`(3)'
     Only on MacOS platforms; requires the standard MacPython `ic'
     module, described in the  manual.

* Menu:

* Browser Controller Objects::


File: python-lib.info,  Node: Browser Controller Objects,  Prev: webbrowser,  Up: webbrowser

Browser Controller Objects
--------------------------

Browser controllers provide two methods which parallel two of the
module-level convenience functions:

`open(url[, new])'
     Display URL using the browser handled by this controller.  If NEW
     is true, a new browser window is opened if possible.

`open_new(url)'
     Open URL in a new window of the browser handled by this
     controller, if possible, otherwise, open URL in the only browser
     window.


File: python-lib.info,  Node: cgi,  Next: cgitb,  Prev: webbrowser,  Up: Internet Protocols and Support

Common Gateway Interface support.
=================================

Common Gateway Interface support, used to interpret forms in
server-side scripts.

Support module for Common Gateway Interface (CGI) scripts.

This module defines a number of utilities for use by CGI scripts
written in Python.

* Menu:

* cgi-intro::
* Using the cgi module::
* Higher Level Interface::
* Old classes::
* Functions in cgi module::
* Caring about security::
* Installing your CGI script on a UNIX system::
* Testing your CGI script::
* Debugging CGI scripts::
* Common problems and solutions::


File: python-lib.info,  Node: cgi-intro,  Next: Using the cgi module,  Prev: cgi,  Up: cgi

Introduction
------------

A CGI script is invoked by an HTTP server, usually to process user
input submitted through an HTML `<FORM>' or `<ISINDEX>' element.

Most often, CGI scripts live in the server's special `cgi-bin'
directory.  The HTTP server places all sorts of information about the
request (such as the client's hostname, the requested URL, the query
string, and lots of other goodies) in the script's shell environment,
executes the script, and sends the script's output back to the client.

The script's input is connected to the client too, and sometimes the
form data is read this way; at other times the form data is passed via
the "query string" part of the URL.  This module is intended to take
care of the different cases and provide a simpler interface to the
Python script.  It also provides a number of utilities that help in
debugging scripts, and the latest addition is support for file uploads
from a form (if your browser supports it -- Grail 0.3 and Netscape 2.0
do).

The output of a CGI script should consist of two sections, separated by
a blank line.  The first section contains a number of headers, telling
the client what kind of data is following.  Python code to generate a
minimal header section looks like this:

     print "Content-Type: text/html"     # HTML is following
     print                               # blank line, end of headers

The second section is usually HTML, which allows the client software to
display nicely formatted text with header, in-line images, etc.  Here's
Python code that prints a simple piece of HTML:

     print "<TITLE>CGI script output</TITLE>"
     print "<H1>This is my first CGI script</H1>"
     print "Hello, world!"


File: python-lib.info,  Node: Using the cgi module,  Next: Higher Level Interface,  Prev: cgi-intro,  Up: cgi

Using the cgi module
--------------------

Begin by writing `import cgi'.  Do not use `from cgi import *' -- the
module defines all sorts of names for its own use or for backward
compatibility that you don't want in your namespace.

When you write a new script, consider adding the line:

     import cgitb; cgitb.enable()

This activates a special exception handler that will display detailed
reports in the Web browser if any errors occur.  If you'd rather not
show the guts of your program to users of your script, you can have the
reports saved to files instead, with a line like this:

     import cgitb; cgitb.enable(display=0, logdir="/tmp")

It's very helpful to use this feature during script development.  The
reports produced by `cgitb' provide information that can save you a lot
of time in tracking down bugs.  You can always remove the `cgitb' line
later when you have tested your script and are confident that it works
correctly.

To get at submitted form data, it's best to use the `FieldStorage'
class.  The other classes defined in this module are provided mostly
for backward compatibility.  Instantiate it exactly once, without
arguments.  This reads the form contents from standard input or the
environment (depending on the value of various environment variables
set according to the CGI standard).  Since it may consume standard
input, it should be instantiated only once.

The `FieldStorage' instance can be indexed like a Python dictionary,
and also supports the standard dictionary methods `has_key()' and
`keys()'.  The built-in `len()' is also supported.  Form fields
containing empty strings are ignored and do not appear in the
dictionary; to keep such values, provide a true value for the optional
KEEP_BLANK_VALUES keyword parameter when creating the `FieldStorage'
instance.

For instance, the following code (which assumes that the `Content-Type'
header and blank line have already been printed) checks that the fields
`name' and `addr' are both set to a non-empty string:

     form = cgi.FieldStorage()
     if not (form.has_key("name") and form.has_key("addr")):
         print "<H1>Error</H1>"
         print "Please fill in the name and addr fields."
         return
     print "<p>name:", form["name"].value
     print "<p>addr:", form["addr"].value
     ...further form processing here...

Here the fields, accessed through `form[KEY]', are themselves instances
of `FieldStorage' (or `MiniFieldStorage', depending on the form
encoding).  The `value' attribute of the instance yields the string
value of the field.  The `getvalue()' method returns this string value
directly; it also accepts an optional second argument as a default to
return if the requested key is not present.

If the submitted form data contains more than one field with the same
name, the object retrieved by `form[KEY]' is not a `FieldStorage' or
`MiniFieldStorage' instance but a list of such instances.  Similarly,
in this situation, `form.getvalue(KEY)' would return a list of strings.
If you expect this possibility (when your HTML form contains multiple
fields with the same name), use the `isinstance()' built-in function to
determine whether you have a single instance or a list of instances.
For example, this code concatenates any number of username fields,
separated by commas:

     value = form.getvalue("username", "")
     if isinstance(value, list):
         # Multiple username fields specified
         usernames = ",".join(value)
     else:
         # Single or no username field specified
         usernames = value

If a field represents an uploaded file, accessing the value via the
`value' attribute or the `getvalue()' method reads the entire file in
memory as a string.  This may not be what you want.  You can test for
an uploaded file by testing either the `filename' attribute or the
`file' attribute.  You can then read the data at leisure from the
`file' attribute:

     fileitem = form["userfile"]
     if fileitem.file:
         # It's an uploaded file; count lines
         linecount = 0
         while 1:
             line = fileitem.file.readline()
             if not line: break
             linecount = linecount + 1

The file upload draft standard entertains the possibility of uploading
multiple files from one field (using a recursive `multipart/*'
encoding).  When this occurs, the item will be a dictionary-like
`FieldStorage' item.  This can be determined by testing its `type'
attribute, which should be `multipart/form-data' (or perhaps another
MIME type matching `multipart/*').  In this case, it can be iterated
over recursively just like the top-level form object.

When a form is submitted in the "old" format (as the query string or as
a single data part of type `application/x-www-form-urlencoded'), the
items will actually be instances of the class `MiniFieldStorage'.  In
this case, the `list', `file', and `filename' attributes are always
`None'.

