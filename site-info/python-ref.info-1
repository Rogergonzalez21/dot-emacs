This is python-ref.info, produced by makeinfo version 4.3 from
python-ref.texi.

October 3, 2003


File: python-ref.info,  Node: Top,  Next: Front Matter,  Prev: (dir),  Up: (dir)

Python Reference Manual
***********************

* Menu:

* Front Matter::
* Introduction::
* Lexical analysis::
* Data model::
* Execution model::
* Expressions::
* Simple statements::
* Compound statements::
* Top-level components::
* History and License::
* Module Index::
* Class-Exception-Object Index::
* Function-Method-Variable Index::
* Miscellaneous Index::


File: python-ref.info,  Node: Front Matter,  Next: Introduction,  Prev: Top,  Up: Top

Front Matter
************

Copyright (C) 2001, 2002, 2003 Python Software Foundation.  All rights
reserved.

Copyright (C) 2000 BeOpen.com.  All rights reserved.

Copyright (C) 1995-2000 Corporation for National Research Initiatives.
All rights reserved.

Copyright (C) 1991-1995 Stichting Mathematisch Centrum.  All rights
reserved.

See the end of this document for complete license and permissions
information.

     Python is an interpreted, object-oriented, high-level programming
     language with dynamic semantics.  Its high-level built in data
     structures, combined with dynamic typing and dynamic binding, make
     it very attractive for rapid application development, as well as
     for use as a scripting or glue language to connect existing
     components together.  Python's simple, easy to learn syntax
     emphasizes readability and therefore reduces the cost of program
     maintenance.  Python supports modules and packages, which
     encourages program modularity and code reuse.  The Python
     interpreter and the extensive standard library are available in
     source or binary form without charge for all major platforms, and
     can be freely distributed.

     This reference manual describes the syntax and "core semantics" of
     the language.  It is terse, but attempts to be exact and complete.
     The semantics of non-essential built-in object types and of the
     built-in functions and modules are described in the .  For an
     informal introduction to the language, see the .  For C or C++
     programmers, two additional manuals exist:  describes the
     high-level picture of how to write a Python extension module, and
     the  describes the interfaces available to C/C++ programmers in
     detail.



File: python-ref.info,  Node: Introduction,  Next: Lexical analysis,  Prev: Front Matter,  Up: Top

Introduction
************

This reference manual describes the Python programming language.  It is
not intended as a tutorial.

While I am trying to be as precise as possible, I chose to use English
rather than formal specifications for everything except syntax and
lexical analysis.  This should make the document more understandable to
the average reader, but will leave room for ambiguities.  Consequently,
if you were coming from Mars and tried to re-implement Python from this
document alone, you might have to guess things and in fact you would
probably end up implementing quite a different language.  On the other
hand, if you are using Python and wonder what the precise rules about a
particular area of the language are, you should definitely be able to
find them here.  If you would like to see a more formal definition of
the language, maybe you could volunteer your time -- or invent a
cloning machine :-).

It is dangerous to add too many implementation details to a language
reference document -- the implementation may change, and other
implementations of the same language may work differently.  On the
other hand, there is currently only one Python implementation in
widespread use (although a second one now exists!), and its particular
quirks are sometimes worth being mentioned, especially where the
implementation imposes additional limitations.  Therefore, you'll find
short "implementation notes" sprinkled throughout the text.

Every Python implementation comes with a number of built-in and
standard modules.  These are not documented here, but in the separate
document.  A few built-in modules are mentioned when they interact in a
significant way with the language definition.

* Menu:

* Notation::


File: python-ref.info,  Node: Notation,  Prev: Introduction,  Up: Introduction

Notation
========

The descriptions of lexical analysis and syntax use a modified BNF
grammar notation.  This uses the following style of definition:

     name:           lc_letter (lc_letter | "_")*
     lc_letter:      "a"..."z"

The first line says that a `name' is an `lc_letter' followed by a
sequence of zero or more `lc_letter's and underscores.  An `lc_letter'
in turn is any of the single characters `a' through `z'.  (This rule is
actually adhered to for the names defined in lexical and grammar rules
in this document.)

Each rule begins with a name (which is the name defined by the rule)
and a colon.  A vertical bar (`|') is used to separate alternatives; it
is the least binding operator in this notation.  A star (`*') means
zero or more repetitions of the preceding item; likewise, a plus (`+')
means one or more repetitions, and a phrase enclosed in square brackets
(`[ ]') means zero or one occurrences (in other words, the enclosed
phrase is optional).  The `*' and `+' operators bind as tightly as
possible; parentheses are used for grouping.  Literal strings are
enclosed in quotes.  White space is only meaningful to separate tokens.
Rules are normally contained on a single line; rules with many
alternatives may be formatted alternatively with each line after the
first beginning with a vertical bar.

In lexical definitions (as the example above), two more conventions are
used: Two literal characters separated by three dots mean a choice of
any single character in the given (inclusive) range of ASCII
characters.  A phrase between angular brackets (`<...>') gives an
informal description of the symbol defined; e.g., this could be used to
describe the notion of `control character' if needed.

Even though the notation used is almost the same, there is a big
difference between the meaning of lexical and syntactic definitions: a
lexical definition operates on the individual characters of the input
source, while a syntax definition operates on the stream of tokens
generated by the lexical analysis.  All uses of BNF in the next chapter
("Lexical Analysis") are lexical definitions; uses in subsequent
chapters are syntactic definitions.


File: python-ref.info,  Node: Lexical analysis,  Next: Data model,  Prev: Introduction,  Up: Top

Lexical analysis
****************

A Python program is read by a _parser_.  Input to the parser is a
stream of _tokens_, generated by the _lexical analyzer_.  This chapter
describes how the lexical analyzer breaks a file into tokens.

Python uses the 7-bit ASCII character set for program text.  _Added in
Python version 2.3_ For compatibility with older versions, Python only
warns if it finds 8-bit characters; those warnings should be corrected
by either declaring an explicit encoding, or using escape sequences if
those bytes are binary data, instead of characters.

The run-time character set depends on the I/O devices connected to the
program but is generally a superset of ASCII.

*Future compatibility note:* It may be tempting to assume that the
character set for 8-bit characters is ISO Latin-1 (an ASCII superset
that covers most western languages that use the Latin alphabet), but it
is possible that in the future Unicode text editors will become common.
These generally use the UTF-8 encoding, which is also an ASCII
superset, but with very different use for the characters with ordinals
128-255.  While there is no consensus on this subject yet, it is unwise
to assume either Latin-1 or UTF-8, even though the current
implementation appears to favor Latin-1.  This applies both to the
source character set and the run-time character set.

* Menu:

* Line structure::
* Other tokens::
* Identifiers and keywords::
* Literals::
* Operators::
* Delimiters::


File: python-ref.info,  Node: Line structure,  Next: Other tokens,  Prev: Lexical analysis,  Up: Lexical analysis

Line structure
==============

A Python program is divided into a number of _logical lines_.

* Menu:

* Logical lines::
* Physical lines::
* Comments::
* Encoding declarations::
* Explicit line joining::
* Implicit line joining::
* Blank lines::
* Indentation::
* Whitespace between tokens::


File: python-ref.info,  Node: Logical lines,  Next: Physical lines,  Prev: Line structure,  Up: Line structure

Logical lines
-------------

The end of a logical line is represented by the token NEWLINE.
Statements cannot cross logical line boundaries except where NEWLINE is
allowed by the syntax (e.g., between statements in compound statements).
A logical line is constructed from one or more _physical lines_ by
following the explicit or implicit _line joining_ rules.


File: python-ref.info,  Node: Physical lines,  Next: Comments,  Prev: Logical lines,  Up: Line structure

Physical lines
--------------

A physical line ends in whatever the current platform's convention is
for terminating lines.  On UNIX, this is the ASCII LF (linefeed)
character.  On Windows, it is the ASCII sequence CR LF (return followed
by linefeed).  On Macintosh, it is the ASCII CR (return) character.


File: python-ref.info,  Node: Comments,  Next: Encoding declarations,  Prev: Physical lines,  Up: Line structure

Comments
--------

A comment starts with a hash character (`#') that is not part of a
string literal, and ends at the end of the physical line.  A comment
signifies the end of the logical line unless the implicit line joining
rules are invoked.  Comments are ignored by the syntax; they are not
tokens.


File: python-ref.info,  Node: Encoding declarations,  Next: Explicit line joining,  Prev: Comments,  Up: Line structure

Encoding declarations
---------------------

If a comment in the first or second line of the Python script matches
the regular expression "coding[=:]\s*([\w-_.]+)", this comment is
processed as an encoding declaration; the first group of this
expression names the encoding of the source code file. The recommended
forms of this expression are

     # -*- coding: <encoding-name> -*-

which is recognized also by GNU Emacs, and

     # vim:fileencoding=<encoding-name>

which is recognized by Bram Moolenar's VIM. In addition, if the first
bytes of the file are the UTF-8 byte-order mark (`'\xef\xbb\xbf''), the
declared file encoding is UTF-8 (this is supported, among others, by
Microsoft's `notepad').

If an encoding is declared, the encoding name must be recognized by
Python. The encoding is used for all lexical analysis, in particular to
find the end of a string, and to interpret the contents of Unicode
literals.  String literals are converted to Unicode for syntactical
analysis, then converted back to their original encoding before
interpretation starts. The encoding declaration must appear on a line
of its own.


File: python-ref.info,  Node: Explicit line joining,  Next: Implicit line joining,  Prev: Encoding declarations,  Up: Line structure

Explicit line joining
---------------------

Two or more physical lines may be joined into logical lines using
backslash characters (`\'), as follows: when a physical line ends in a
backslash that is not part of a string literal or comment, it is joined
with the following forming a single logical line, deleting the
backslash and the following end-of-line character.  For example:
     if 1900 < year < 2100 and 1 <= month <= 12 \
        and 1 <= day <= 31 and 0 <= hour < 24 \
        and 0 <= minute < 60 and 0 <= second < 60:   # Looks like a valid date
             return 1

A line ending in a backslash cannot carry a comment.  A backslash does
not continue a comment.  A backslash does not continue a token except
for string literals (i.e., tokens other than string literals cannot be
split across physical lines using a backslash).  A backslash is illegal
elsewhere on a line outside a string literal.


File: python-ref.info,  Node: Implicit line joining,  Next: Blank lines,  Prev: Explicit line joining,  Up: Line structure

Implicit line joining
---------------------

Expressions in parentheses, square brackets or curly braces can be
split over more than one physical line without using backslashes.  For
example:

     month_names = ['Januari', 'Februari', 'Maart',      # These are the
                    'April',   'Mei',      'Juni',       # Dutch names
                    'Juli',    'Augustus', 'September',  # for the months
                    'Oktober', 'November', 'December']   # of the year

Implicitly continued lines can carry comments.  The indentation of the
continuation lines is not important.  Blank continuation lines are
allowed.  There is no NEWLINE token between implicit continuation
lines.  Implicitly continued lines can also occur within triple-quoted
strings (see below); in that case they cannot carry comments.


File: python-ref.info,  Node: Blank lines,  Next: Indentation,  Prev: Implicit line joining,  Up: Line structure

Blank lines
-----------

A logical line that contains only spaces, tabs, formfeeds and possibly
a comment, is ignored (i.e., no NEWLINE token is generated).  During
interactive input of statements, handling of a blank line may differ
depending on the implementation of the read-eval-print loop.  In the
standard implementation, an entirely blank logical line (i.e. one
containing not even whitespace or a comment) terminates a multi-line
statement.


File: python-ref.info,  Node: Indentation,  Next: Whitespace between tokens,  Prev: Blank lines,  Up: Line structure

Indentation
-----------

Leading whitespace (spaces and tabs) at the beginning of a logical line
is used to compute the indentation level of the line, which in turn is
used to determine the grouping of statements.

First, tabs are replaced (from left to right) by one to eight spaces
such that the total number of characters up to and including the
replacement is a multiple of eight (this is intended to be the same
rule as used by UNIX).  The total number of spaces preceding the first
non-blank character then determines the line's indentation.
Indentation cannot be split over multiple physical lines using
backslashes; the whitespace up to the first backslash determines the
indentation.

*Cross-platform compatibility note:* because of the nature of text
editors on non-UNIX platforms, it is unwise to use a mixture of spaces
and tabs for the indentation in a single source file.  It should also
be noted that different platforms may explicitly limit the maximum
indentation level.

A formfeed character may be present at the start of the line; it will
be ignored for the indentation calculations above.  Formfeed characters
occurring elsewhere in the leading whitespace have an undefined effect
(for instance, they may reset the space count to zero).

The indentation levels of consecutive lines are used to generate INDENT
and DEDENT tokens, using a stack, as follows.

Before the first line of the file is read, a single zero is pushed on
the stack; this will never be popped off again.  The numbers pushed on
the stack will always be strictly increasing from bottom to top.  At
the beginning of each logical line, the line's indentation level is
compared to the top of the stack.  If it is equal, nothing happens.  If
it is larger, it is pushed on the stack, and one INDENT token is
generated.  If it is smaller, it _must_ be one of the numbers occurring
on the stack; all numbers on the stack that are larger are popped off,
and for each number popped off a DEDENT token is generated.  At the end
of the file, a DEDENT token is generated for each number remaining on
the stack that is larger than zero.

Here is an example of a correctly (though confusingly) indented piece
of Python code:

     def perm(l):
             # Compute the list of all permutations of l
         if len(l) <= 1:
                       return [l]
         r = []
         for i in range(len(l)):
                  s = l[:i] + l[i+1:]
                  p = perm(s)
                  for x in p:
                   r.append(l[i:i+1] + x)
         return r

The following example shows various indentation errors:

      def perm(l):                       # error: first line indented
     for i in range(len(l)):             # error: not indented
         s = l[:i] + l[i+1:]
             p = perm(l[:i] + l[i+1:])   # error: unexpected indent
             for x in p:
                     r.append(l[i:i+1] + x)
                 return r                # error: inconsistent dedent

(Actually, the first three errors are detected by the parser; only the
last error is found by the lexical analyzer -- the indentation of
`return r' does not match a level popped off the stack.)


File: python-ref.info,  Node: Whitespace between tokens,  Prev: Indentation,  Up: Line structure

Whitespace between tokens
-------------------------

Except at the beginning of a logical line or in string literals, the
whitespace characters space, tab and formfeed can be used
interchangeably to separate tokens.  Whitespace is needed between two
tokens only if their concatenation could otherwise be interpreted as a
different token (e.g., ab is one token, but a b is two tokens).


File: python-ref.info,  Node: Other tokens,  Next: Identifiers and keywords,  Prev: Line structure,  Up: Lexical analysis

Other tokens
============

Besides NEWLINE, INDENT and DEDENT, the following categories of tokens
exist: _identifiers_, _keywords_, _literals_, _operators_, and
_delimiters_.  Whitespace characters (other than line terminators,
discussed earlier) are not tokens, but serve to delimit tokens.  Where
ambiguity exists, a token comprises the longest possible string that
forms a legal token, when read from left to right.


File: python-ref.info,  Node: Identifiers and keywords,  Next: Literals,  Prev: Other tokens,  Up: Lexical analysis

Identifiers and keywords
========================

Identifiers (also referred to as _names_) are described by the following
lexical definitions:

`identifier (`letter'|"_") (`letter' | `digit' | "_")*'

`letter `lowercase' | `uppercase''

`lowercase "a"..."z"'

`uppercase "A"..."Z"'

`digit "0"..."9"'
Identifiers are unlimited in length.  Case is significant.

* Menu:

* Keywords::
* Reserved classes of identifiers::


File: python-ref.info,  Node: Keywords,  Next: Reserved classes of identifiers,  Prev: Identifiers and keywords,  Up: Identifiers and keywords

Keywords
--------

The following identifiers are used as reserved words, or _keywords_ of
the language, and cannot be used as ordinary identifiers.  They must be
spelled exactly as written here:

     and       del       for       is        raise
     assert    elif      from      lambda    return
     break     else      global    not       try
     class     except    if        or        while
     continue  exec      import    pass      yield
     def       finally   in        print

Note that although the identifier `as' can be used as part of the
syntax of `import' statements, it is not currently a reserved word.

In some future version of Python, the identifiers `as' and `None' will
both become keywords.


File: python-ref.info,  Node: Reserved classes of identifiers,  Prev: Keywords,  Up: Identifiers and keywords

Reserved classes of identifiers
-------------------------------

Certain classes of identifiers (besides keywords) have special
meanings.  These classes are identified by the patterns of leading and
trailing underscore characters:

``_*''
     Not imported by `from MODULE import *'.  The special identifier
     `_' is used in the interactive interpreter to store the result of
     the last evaluation; it is stored in the `__builtin__' module.
     When not in interactive mode, `_' has no special meaning and is
     not defined.  See section~*Note import statement::, "The `import'
     statement."

     _Note:_ The name `_' is often used in conjunction with
     internationalization; refer to the documentation for the `gettext'
     module for more information on this convention.

``__*__''
     System-defined names.  These names are defined by the interpreter
     and it's implementation (including the standard library);
     applications should not expect to define additional names using
     this convention.  The set of names of this class defined by Python
     may be extended in future versions.  See section~*Note Special
     method names::, "Special method names."

``__*''
     Class-private names.  Names in this category, when used within the
     context of a class definition, are re-written to use a mangled for
     to help avoid name clashes between "private" attributes of base
     and derived classes.  See section~*Note Identifiers Names::,
     "Identifiers (Names)."


File: python-ref.info,  Node: Literals,  Next: Operators,  Prev: Identifiers and keywords,  Up: Lexical analysis

Literals
========

Literals are notations for constant values of some built-in types.

* Menu:

* String literals::
* String literal concatenation::
* Numeric literals::
* Integer and long integer literals::
* Floating point literals::
* Imaginary literals::


File: python-ref.info,  Node: String literals,  Next: String literal concatenation,  Prev: Literals,  Up: Literals

String literals
---------------

String literals are described by the following lexical definitions:

`stringliteral [`stringprefix'](`shortstring' | `longstring')'

`stringprefix "r" | "u" | "ur" | "R" | "U" | "UR" | "Ur" | "uR"'

`shortstring "'" `shortstringitem'* "'" | '"' `shortstringitem'* '"''

`longstring "'''" `longstringitem'* "'''"'

` | '"""' `longstringitem'* '"""''

`shortstringitem `shortstringchar' | `escapeseq''

`longstringitem `longstringchar' | `escapeseq''

`shortstringchar <any ASCII character except "\" or newline or the quote>'

`longstringchar <any ASCII character except "\">'

`escapeseq "\" <any ASCII character>'
One syntactic restriction not indicated by these productions is that
whitespace is not allowed between the `stringprefix' and the rest of
the string literal.

In plain English: String literals can be enclosed in matching single
quotes (`'') or double quotes (`"').  They can also be enclosed in
matching groups of three single or double quotes (these are generally
referred to as _triple-quoted strings_).  The backslash (`\') character
is used to escape characters that otherwise have a special meaning,
such as newline, backslash itself, or the quote character.  String
literals may optionally be prefixed with a letter `r' or `R'; such
strings are called "raw strings"  and use different rules for
interpreting backslash escape sequences.  A prefix of `u' or `U' makes
the string a Unicode string.  Unicode strings use the Unicode character
set as defined by the Unicode Consortium and ISO~10646.  Some additional
escape sequences, described below, are available in Unicode strings.
The two prefix characters may be combined; in this case, `u' must
appear before `r'.

In triple-quoted strings, unescaped newlines and quotes are allowed
(and are retained), except that three unescaped quotes in a row
terminate the string.  (A "quote" is the character used to open the
string, i.e. either `'' or `"'.)

Unless an `r' or `R' prefix is present, escape sequences in strings are
interpreted according to rules similar to those used by Standard C.
The recognized escape sequences are:

Escape Sequence          Meaning                  Notes
------                   -----                    -----
\NEWLINE                 Ignored                  
\\                       Backslash (`\')          
\'                       Single quote (`'')       
\"                       Double quote (`"')       
\a                       ASCII Bell (BEL)         
\b                       ASCII Backspace (BS)     
\f                       ASCII Formfeed (FF)      
\n                       ASCII Linefeed (LF)      
\N{NAME}                 Character named NAME in  
                         the Unicode database     
                         (Unicode only)           
\r                       ASCII Carriage Return    
                         (CR)                     
\t                       ASCII Horizontal Tab     
                         (TAB)                    
\uXXXX                   Character with 16-bit    (1)
                         hex value XXXX (Unicode  
                         only)                    
\UXXXXXXXX               Character with 32-bit    (2)
                         hex value XXXXXXXX       
                         (Unicode only)           
\v                       ASCII Vertical Tab (VT)  
\OOO                     ASCII character with     (3)
                         octal value OOO          
\xHH                     ASCII character with     (4)
                         hex value HH             

Notes:

   * (1) Individual code units which form parts of a surrogate pair can
     be encoded using this escape sequence.

   * (2) Any Unicode character can be encoded this way, but characters
     outside the Basic Multilingual Plane (BMP) will be encoded using a
     surrogate pair if Python is compiled to use 16-bit code units (the
     default).  Individual code units which form parts of a surrogate
     pair can be encoded using this escape sequence.

   * (3) As in Standard C, up to three octal digits are accepted.

   * (4) Unlike in Standard C, at most two hex digits are accepted.

Unlike Standard C, all unrecognized escape sequences are left in the
string unchanged, i.e., _the backslash is left in the string_.  (This
behavior is useful when debugging: if an escape sequence is mistyped,
the resulting output is more easily recognized as broken.)  It is also
important to note that the escape sequences marked as "(Unicode only)"
in the table above fall into the category of unrecognized escapes for
non-Unicode string literals.

When an `r' or `R' prefix is present, a character following a backslash
is included in the string without change, and _all backslashes are left
in the string_.  For example, the string literal `r"\n"' consists of
two characters: a backslash and a lowercase `n'.  String quotes can be
escaped with a backslash, but the backslash remains in the string; for
example, `r"\""' is a valid string literal consisting of two
characters: a backslash and a double quote; `r"\"' is not a valid
string literal (even a raw string cannot end in an odd number of
backslashes).  Specifically, _a raw string cannot end in a single
backslash_ (since the backslash would escape the following quote
character).  Note also that a single backslash followed by a newline is
interpreted as those two characters as part of the string, _not_ as a
line continuation.

When an `r' or `R' prefix is used in conjunction with a `u' or `U'
prefix, then the `\uXXXX' escape sequence is processed while _all other
backslashes are left in the string_.  For example, the string literal
`ur"\u0062\n"' consists of three Unicode characters: `LATIN SMALL
LETTER B', `REVERSE SOLIDUS', and `LATIN SMALL LETTER N'.  Backslashes
can be escaped with a preceding backslash; however, both remain in the
string.  As a result, `\uXXXX' escape sequences are only recognized
when there are an odd number of backslashes.


File: python-ref.info,  Node: String literal concatenation,  Next: Numeric literals,  Prev: String literals,  Up: Literals

String literal concatenation
----------------------------

Multiple adjacent string literals (delimited by whitespace), possibly
using different quoting conventions, are allowed, and their meaning is
the same as their concatenation.  Thus, `"hello" 'world'' is equivalent
to `"helloworld"'.  This feature can be used to reduce the number of
backslashes needed, to split long strings conveniently across long
lines, or even to add comments to parts of strings, for example:

     re.compile("[A-Za-z_]"       # letter or underscore
                "[A-Za-z0-9_]*"   # letter, digit or underscore
               )

Note that this feature is defined at the syntactical level, but
implemented at compile time.  The `+' operator must be used to
concatenate string expressions at run time.  Also note that literal
concatenation can use different quoting styles for each component (even
mixing raw strings and triple quoted strings).


File: python-ref.info,  Node: Numeric literals,  Next: Integer and long integer literals,  Prev: String literal concatenation,  Up: Literals

Numeric literals
----------------

There are four types of numeric literals: plain integers, long
integers, floating point numbers, and imaginary numbers.  There are no
complex literals (complex numbers can be formed by adding a real number
and an imaginary number).

Note that numeric literals do not include a sign; a phrase like `-1' is
actually an expression composed of the unary operator ``-'' and the
literal `1'.


File: python-ref.info,  Node: Integer and long integer literals,  Next: Floating point literals,  Prev: Numeric literals,  Up: Literals

Integer and long integer literals
---------------------------------

Integer and long integer literals are described by the following
lexical definitions:

`longinteger `integer' ("l" | "L")'

`integer `decimalinteger' | `octinteger' | `hexinteger''

`decimalinteger `nonzerodigit' `digit'* | "0"'

`octinteger "0" `octdigit'+'

`hexinteger "0" ("x" | "X") `hexdigit'+'

`nonzerodigit "1"..."9"'

`octdigit "0"..."7"'

`hexdigit `digit' | "a"..."f" | "A"..."F"'
Although both lower case `l' and upper case `L' are allowed as suffix
for long integers, it is strongly recommended to always use `L', since
the letter `l' looks too much like the digit `1'.

Plain integer decimal literals that are above the largest representable
plain integer (e.g., 2147483647 when using 32-bit arithmetic) are
accepted as if they were long integers instead.  Octal and hexadecimal
literals behave similarly, but when in the range just above the largest
representable plain integer but below the largest unsigned 32-bit
number (on a machine using 32-bit arithmetic), 4294967296, they are
taken as the negative plain integer obtained by subtracting 4294967296
from their unsigned value.  There is no limit for long integer literals
apart from what can be stored in available memory.  For example,
0xdeadbeef is taken, on a 32-bit machine, as the value -559038737,
while 0xdeadbeeffeed is taken as the value 244837814107885L.

Some examples of plain integer literals (first row) and long integer
literals (second and third rows):

     7     2147483647                        0177    0x80000000
     3L    79228162514264337593543950336L    0377L   0x100000000L
           79228162514264337593543950336             0xdeadbeeffeed


File: python-ref.info,  Node: Floating point literals,  Next: Imaginary literals,  Prev: Integer and long integer literals,  Up: Literals

Floating point literals
-----------------------

Floating point literals are described by the following lexical
definitions:

`floatnumber `pointfloat' | `exponentfloat''

`pointfloat [`intpart'] `fraction' | `intpart' "."'

`exponentfloat (`intpart' | `pointfloat') `exponent''

`intpart `digit'+'

`fraction "." `digit'+'

`exponent ("e" | "E") ["+" | "-"] `digit'+'
Note that the integer and exponent parts of floating point numbers can
look like octal integers, but are interpreted using radix 10.  For
example, `077e010' is legal, and denotes the same number as `77e10'.
The allowed range of floating point literals is
implementation-dependent.  Some examples of floating point literals:

     3.14    10.    .001    1e100    3.14e-10    0e0

Note that numeric literals do not include a sign; a phrase like `-1' is
actually an expression composed of the operator `-' and the literal `1'.


File: python-ref.info,  Node: Imaginary literals,  Prev: Floating point literals,  Up: Literals

Imaginary literals
------------------

Imaginary literals are described by the following lexical definitions:

`imagnumber (`floatnumber' | `intpart') ("j" | "J")'
An imaginary literal yields a complex number with a real part of 0.0.
Complex numbers are represented as a pair of floating point numbers and
have the same restrictions on their range.  To create a complex number
with a nonzero real part, add a floating point number to it, e.g.,
`(3+4j)'.  Some examples of imaginary literals:

     3.14j   10.j    10j     .001j   1e100j  3.14e-10j


File: python-ref.info,  Node: Operators,  Next: Delimiters,  Prev: Literals,  Up: Lexical analysis

Operators
=========

The following tokens are operators:

     +       -       *       **      /       //      %
     <<      >>      &       |       ^       ~
     <       >       <=      >=      ==      !=      <>

The comparison operators `<>' and `!=' are alternate spellings of the
same operator.  `!=' is the preferred spelling; `<>' is obsolescent.


File: python-ref.info,  Node: Delimiters,  Prev: Operators,  Up: Lexical analysis

Delimiters
==========

The following tokens serve as delimiters in the grammar:

     (       )       [       ]       {       }
     ,       :       .       `       =       ;
     +=      -=      *=      /=      //=     %=
     &=      |=      ^=      >>=     <<=     **=

The period can also occur in floating-point and imaginary literals.  A
sequence of three periods has a special meaning as an ellipsis in
slices.  The second half of the list, the augmented assignment
operators, serve lexically as delimiters, but also perform an operation.

The following printing ASCII characters have special meaning as part of
other tokens or are otherwise significant to the lexical analyzer:

     '       "       #       \

The following printing ASCII characters are not used in Python.  Their
occurrence outside string literals and comments is an unconditional
error:

     @       $       ?


File: python-ref.info,  Node: Data model,  Next: Execution model,  Prev: Lexical analysis,  Up: Top

Data model
**********

* Menu:

* Objects::
* standard type hierarchy::
* Special method names::


File: python-ref.info,  Node: Objects,  Next: standard type hierarchy,  Prev: Data model,  Up: Data model

Objects, values and types
=========================

"Objects" are Python's abstraction for data.  All data in a Python
program is represented by objects or by relations between objects.  (In
a sense, and in conformance to Von Neumann's model of a "stored program
computer," code is also represented by objects.)

Every object has an identity, a type and a value.  An object's
_identity_ never changes once it has been created; you may think of it
as the object's address in memory.  The ``is'' operator compares the
identity of two objects; the `id()'  function returns an integer
representing its identity (currently implemented as its address).  An
object's "type" is also unchangeable.(1) An object's type determines
the operations that the object supports (e.g., "does it have a
length?") and also defines the possible values for objects of that
type.  The `type()'  function returns an object's type (which is an
object itself).  The _value_ of some objects can change.  Objects whose
value can change are said to be _mutable_; objects whose value is
unchangeable once they are created are called _immutable_.  (The value
of an immutable container object that contains a reference to a mutable
object can change when the latter's value is changed; however the
container is still considered immutable, because the collection of
objects it contains cannot be changed.  So, immutability is not
strictly the same as having an unchangeable value, it is more subtle.)
An object's mutability is determined by its type; for instance,
numbers, strings and tuples are immutable, while dictionaries and lists
are mutable.

Objects are never explicitly destroyed; however, when they become
unreachable they may be garbage-collected.  An implementation is
allowed to postpone garbage collection or omit it altogether -- it is a
matter of implementation quality how garbage collection is implemented,
as long as no objects are collected that are still reachable.
(Implementation note: the current implementation uses a
reference-counting scheme with (optional) delayed detection of
cyclically linked garbage, which collects most objects as soon as they
become unreachable, but is not guaranteed to collect garbage containing
circular references.  See the  for information on controlling the
collection of cyclic garbage.)

Note that the use of the implementation's tracing or debugging
facilities may keep objects alive that would normally be collectable.
Also note that catching an exception with a ``try'...`except''
statement may keep objects alive.

Some objects contain references to "external" resources such as open
files or windows.  It is understood that these resources are freed when
the object is garbage-collected, but since garbage collection is not
guaranteed to happen, such objects also provide an explicit way to
release the external resource, usually a `close()' method.  Programs
are strongly recommended to explicitly close such objects.  The
``try'...`finally'' statement provides a convenient way to do this.

Some objects contain references to other objects; these are called
_containers_.  Examples of containers are tuples, lists and
dictionaries.  The references are part of a container's value.  In most
cases, when we talk about the value of a container, we imply the
values, not the identities of the contained objects; however, when we
talk about the mutability of a container, only the identities of the
immediately contained objects are implied.  So, if an immutable
container (like a tuple) contains a reference to a mutable object, its
value changes if that mutable object is changed.

Types affect almost all aspects of object behavior.  Even the importance
of object identity is affected in some sense: for immutable types,
operations that compute new values may actually return a reference to
any existing object with the same type and value, while for mutable
objects this is not allowed.  E.g., after `a = 1; b = 1', `a' and `b'
may or may not refer to the same object with the value one, depending
on the implementation, but after `c = []; d = []', `c' and `d' are
guaranteed to refer to two different, unique, newly created empty lists.
(Note that `c = d = []' assigns the same object to both `c' and `d'.)

---------- Footnotes ----------

(1) Since Python 2.2, a gradual merging of types and classes has been
started that makes this and a few other assertions made in this manual
not 100% accurate and complete: for example, it _is_ now possible in
some cases to change an object's type, under certain controlled
conditions.  Until this manual undergoes extensive revision, it must
now be taken as authoritative only regarding "classic classes", that
are still the default, for compatibility purposes, in Python 2.2 and
2.3.

