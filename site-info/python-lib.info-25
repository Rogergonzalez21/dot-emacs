This is python-lib.info, produced by makeinfo version 4.3 from
python-lib.texi.

October 3, 2003


File: python-lib.info,  Node: dummy_threading,  Next: Queue,  Prev: dummy_thread,  Up: Optional Operating System Services

Drop-in replacement for the `threading' module
==============================================

Drop-in replacement for the `threading' module.

This module provides a duplicate interface to the `threading' module.
It is meant to be imported when the `thread' module is not provided on
a platform.

Suggested usage is:

     try:
         import threading as _threading
     except ImportError:
         import dummy_threading as _threading

Be careful to not use this module where deadlock might occur from a
thread being created that blocks waiting for another thread to be
created.  This often occurs with blocking I/O.


File: python-lib.info,  Node: Queue,  Next: mmap,  Prev: dummy_threading,  Up: Optional Operating System Services

A synchronized queue class
==========================

A synchronized queue class.

The `Queue' module implements a multi-producer, multi-consumer FIFO
queue.  It is especially useful in threads programming when information
must be exchanged safely between multiple threads.  The `Queue' class
in this module implements all the required locking semantics.  It
depends on the availability of thread support in Python.

See also:
     *Note bisect:: PriorityQueue example using the Queue class

The `Queue' module defines the following class and exception:

`Queue(maxsize)'
     Constructor for the class.  MAXSIZE is an integer that sets the
     upperbound limit on the number of items that can be placed in the
     queue.  Insertion will block once this size has been reached, until
     queue items are consumed.  If MAXSIZE is less than or equal to
     zero, the queue size is infinite.

`Empty'
     Exception raised when non-blocking `get()' (or `get_nowait()') is
     called on a `Queue' object which is empty or locked.

`Full'
     Exception raised when non-blocking `put()' (or `put_nowait()') is
     called on a `Queue' object which is full or locked.

* Menu:

* Queue Objects::


File: python-lib.info,  Node: Queue Objects,  Prev: Queue,  Up: Queue

Queue Objects
-------------

Class `Queue' implements queue objects and has the methods described
below.  This class can be derived from in order to implement other
queue organizations (e.g. stack) but the inheritable interface is not
described here.  See the source code for details.  The public methods
are:

`qsize()'
     Return the approximate size of the queue.  Because of
     multithreading semantics, this number is not reliable.

`empty()'
     Return `True' if the queue is empty, `False' otherwise.  Becauseof
     multithreading semantics, this is not reliable.

`full()'
     Return `True' if the queue is full, `False' otherwise.  Because of
     multithreading semantics, this is not reliable.

`put(item[, block[, timeout]])'
     Put ITEM into the queue. If optional args BLOCK is true and
     TIMEOUT is None (the default), block if necessary until a free
     slot is available. If TIMEOUT is a positive number, it blocks at
     most TIMEOUT seconds and raises the `Full' exception if no free
     slot was available within that time.  Otherwise (BLOCK is false),
     put an item on the queue if a free slot is immediately available,
     else raise the `Full' exception (TIMEOUT is ignored in that case).

     _Added in Python version 2.3_

`put_nowait(item)'
     Equivalent to `put(ITEM, False)'.

`get([block[, timeout]])'
     Remove and return an item from the queue. If optional args BLOCK
     is true and TIMEOUT is None (the default), block if necessary
     until an item is available. If TIMEOUT is a positive number, it
     blocks at most TIMEOUT seconds and raises the `Empty' exception if
     no item was available within that time. Otherwise (BLOCK is
     false), return an item if one is immediately available, else raise
     the `Empty' exception (TIMEOUT is ignored in that case).

     _Added in Python version 2.3_

`get_nowait()'
     Equivalent to `get(False)'.


File: python-lib.info,  Node: mmap,  Next: anydbm,  Prev: Queue,  Up: Optional Operating System Services

Memory-mapped file support
==========================

Interface to memory-mapped files for UNIX and Windows.

Memory-mapped file objects behave like both strings and like file
objects.  Unlike normal string objects, however, these are mutable.
You can use mmap objects in most places where strings are expected; for
example, you can use the `re' module to search through a memory-mapped
file.  Since they're mutable, you can change a single character by
doing `obj[INDEX] = 'a'', or change a substring by assigning to a slice:
`obj[I1:I2] = '...''.  You can also read and write data starting at the
current file position, and `seek()' through the file to different
positions.

A memory-mapped file is created by the `mmap()' function, which is
different on UNIX and on Windows.  In either case you must provide a
file descriptor for a file opened for update.  If you wish to map an
existing Python file object, use its `fileno()' method to obtain the
correct value for the FILENO parameter.  Otherwise, you can open the
file using the `os.open()' function, which returns a file descriptor
directly (the file still needs to be closed when done).

For both the UNIX and Windows versions of the function, ACCESS may be
specified as an optional keyword parameter.  ACCESS accepts one of
three values: `ACCESS_READ', `ACCESS_WRITE', or `ACCESS_COPY' to specify
readonly, write-through or copy-on-write memory respectively.  ACCESS
can be used on both UNIX and Windows.  If ACCESS is not specified,
Windows mmap returns a write-through mapping.  The initial memory
values for all three access types are taken from the specified file.
Assignment to an `ACCESS_READ' memory map raises a `TypeError'
exception.  Assignment to an `ACCESS_WRITE' memory map affects both
memory and the underlying file.  Assigment to an `ACCESS_COPY' memory
map affects memory but does not update the underlying file.

`mmap(fileno, length[, tagname[, access]])'
     *(Windows version)* Maps LENGTH bytes from the file specified by
     the file handle FILENO, and returns a mmap object.  If LENGTH is
     `0', the maximum length of the map will be the current size of the
     file when `mmap()' is called.

     TAGNAME, if specified and not `None', is a string giving a tag
     name for the mapping.  Windows allows you to have many different
     mappings against the same file.  If you specify the name of an
     existing tag, that tag is opened, otherwise a new tag of this name
     is created.  If this parameter is omitted or `None', the mapping
     is created without a name.  Avoiding the use of the tag parameter
     will assist in keeping your code portable between UNIX and Windows.

`mmap(fileno, length[, flags[, prot[, access]]])'
     *(UNIX version)* Maps LENGTH bytes from the file specified by the
     file descriptor FILENO, and returns a mmap object.

     FLAGS specifies the nature of the mapping.  `MAP_PRIVATE' creates
     a private copy-on-write mapping, so changes to the contents of the
     mmap object will be private to this process, and `MAP_SHARED'
     creates a mapping that's shared with all other processes mapping
     the same areas of the file.  The default value is `MAP_SHARED'.

     PROT, if specified, gives the desired memory protection; the two
     most useful values are `PROT_READ' and `PROT_WRITE', to specify
     that the pages may be read or written.  PROT defaults to
     `PROT_READ | PROT_WRITE'.

     ACCESS may be specified in lieu of FLAGS and PROT as an optional
     keyword parameter.  It is an error to specify both FLAGS, PROT and
     ACCESS.  See the description of ACCESS above for information on
     how to use this parameter.

Memory-mapped file objects support the following methods:

`close()'
     Close the file.  Subsequent calls to other methods of the object
     will result in an exception being raised.

`find(string[, start])'
     Returns the lowest index in the object where the substring STRING
     is found.  Returns `-1' on failure.  START is the index at which
     the search begins, and defaults to zero.

`flush([offset, size])'
     Flushes changes made to the in-memory copy of a file back to disk.
     Without use of this call there is no guarantee that changes are
     written back before the object is destroyed.  If OFFSET and SIZE
     are specified, only changes to the given range of bytes will be
     flushed to disk; otherwise, the whole extent of the mapping is
     flushed.

`move(DEST, SRC, COUNT)'
     Copy the COUNT bytes starting at offset SRC to the destination
     index DEST.  If the mmap was created with `ACCESS_READ', then
     calls to move will throw a `TypeError' exception.

`read(NUM)'
     Return a string containing up to NUM bytes starting from the
     current file position; the file position is updated to point after
     the bytes that were returned.

`read_byte()'
     Returns a string of length 1 containing the character at the
     current file position, and advances the file position by 1.

`readline()'
     Returns a single line, starting at the current file position and
     up to the next newline.

`resize(NEWSIZE)'
     If the mmap was created with `ACCESS_READ' or `ACCESS_COPY',
     resizing the map will throw a `TypeError' exception.

`seek(pos[, whence])'
     Set the file's current position.  WHENCE argument is optional and
     defaults to `0' (absolute file positioning); other values are `1'
     (seek relative to the current position) and `2' (seek relative to
     the file's end).

`size()'
     Return the length of the file, which can be larger than the size of
     the memory-mapped area.

`tell()'
     Returns the current position of the file pointer.

`write(STRING)'
     Write the bytes in STRING into memory at the current position of
     the file pointer; the file position is updated to point after the
     bytes that were written. If the mmap was created with
     `ACCESS_READ', then writing to it will throw a `TypeError'
     exception.

`write_byte(BYTE)'
     Write the single-character string BYTE into memory at the current
     position of the file pointer; the file position is advanced by
     `1'.If the mmap was created with `ACCESS_READ', then writing to it
     will throw a `TypeError' exception.


File: python-lib.info,  Node: anydbm,  Next: dbhash,  Prev: mmap,  Up: Optional Operating System Services

Generic access to DBM-style databases
=====================================

Generic interface to DBM-style database modules.

`anydbm' is a generic interface to variants of the DBM database --
`dbhash'  (requires `bsddb' ), `gdbm' , or `dbm' .  If none of these
modules is installed, the slow-but-simple implementation in module
`dumbdbm'  will be used.

`open(filename[, flag[, mode]])'
     Open the database file FILENAME and return a corresponding object.

     If the database file already exists, the `whichdb' module is used
     to determine its type and the appropriate module is used; if it
     does not exist, the first module listed above that can be imported
     is used.

     The optional FLAG argument can be `'r'' to open an existing
     database for reading only, `'w'' to open an existing database for
     reading and writing, `'c'' to create the database if it doesn't
     exist, or `'n'', which will always create a new empty database.
     If not specified, the default value is `'r''.

     The optional MODE argument is the UNIX mode of the file, used only
     when the database has to be created.  It defaults to octal `0666'
     (and will be modified by the prevailing umask).

`error'
     A tuple containing the exceptions that can be raised by each of the
     supported modules, with a unique exception `anydbm.error' as the
     first item -- the latter is used when `anydbm.error' is raised.

The object returned by `open()' supports most of the same functionality
as dictionaries; keys and their corresponding values can be stored,
retrieved, and deleted, and the `has_key()' and `keys()' methods are
available.  Keys and values must always be strings.

See also:
     *Note dbhash:: BSD `db' database interface.  *Note dbm:: Standard
     UNIX database interface.  *Note dumbdbm:: Portable implementation
     of the `dbm' interface.  *Note gdbm:: GNU database interface,
     based on the `dbm' interface.  *Note shelve:: General object
     persistence built on top of  the Python `dbm' interface.  *Note
     whichdb:: Utility module used to determine the type of an existing
     database.


File: python-lib.info,  Node: dbhash,  Next: whichdb,  Prev: anydbm,  Up: Optional Operating System Services

DBM-style interface to the BSD database library
===============================================

DBM-style interface to the BSD database library.

The `dbhash' module provides a function to open databases using the BSD
`db' library.  This module mirrors the interface of the other Python
database modules that provide access to DBM-style databases.  The
`bsddb'  module is required to use `dbhash'.

This module provides an exception and a function:

`error'
     Exception raised on database errors other than `KeyError'.  It is
     a synonym for `bsddb.error'.

`open(path[, flag[, mode]])'
     Open a `db' database and return the database object.  The PATH
     argument is the name of the database file.

     The FLAG argument can be `'r'' (the default), `'w'', `'c'' (which
     creates the database if it doesn't exist), or `'n'' (which always
     creates a new empty database).  For platforms on which the BSD
     `db' library supports locking, an `l' can be appended to indicate
     that locking should be used.

     The optional MODE parameter is used to indicate the UNIX
     permission bits that should be set if a new database must be
     created; this will be masked by the current umask value for the
     process.

See also:
     *Note anydbm:: Generic interface to `dbm'-style databases.  *Note
     bsddb:: Lower-level interface to the BSD `db' library.  *Note
     whichdb:: Utility module used to determine the type of an existing
     database.

* Menu:

* Database Objects::


File: python-lib.info,  Node: Database Objects,  Prev: dbhash,  Up: dbhash

Database Objects
----------------

The database objects returned by `open()' provide the methods common to
all the DBM-style databases and mapping objects.  The following methods
are available in addition to the standard methods.

`first()'
     It's possible to loop over every key/value pair in the database
     using this method   and the `next()' method.  The traversal is
     ordered by the databases internal hash values, and won't be sorted
     by the key values.  This method returns the starting key.

`last()'
     Return the last key/value pair in a database traversal.  This may
     be used to begin a reverse-order traversal; see `previous()'.

`next()'
     Returns the key next key/value pair in a database traversal.  The
     following code prints every key in the database `db', without
     having to create a list in memory that contains them all:

          print db.first()
          for i in xrange(1, len(db)):
              print db.next()

`previous()'
     Returns the previous key/value pair in a forward-traversal of the
     database.  In conjunction with `last()', this may be used to
     implement a reverse-order traversal.

`sync()'
     This method forces any unwritten data to be written to the disk.


File: python-lib.info,  Node: whichdb,  Next: bsddb,  Prev: dbhash,  Up: Optional Operating System Services

Guess which DBM module created a database
=========================================

Guess which DBM-style module created a given database.

The single function in this module attempts to guess which of the
several simple database modules available-`dbm', `gdbm', or
`dbhash'-should be used to open a given file.

`whichdb(filename)'
     Returns one of the following values: `None' if the file can't be
     opened because it's unreadable or doesn't exist; the empty string
     (`''') if the file's format can't be guessed; or a string
     containing the required module name, such as `'dbm'' or `'gdbm''.


File: python-lib.info,  Node: bsddb,  Next: dumbdbm,  Prev: whichdb,  Up: Optional Operating System Services

Interface to Berkeley DB library
================================

Interface to Berkeley DB database library

The `bsddb' module provides an interface to the Berkeley DB library.
Users can create hash, btree or record based library files using the
appropriate open call. Bsddb objects behave generally like
dictionaries.  Keys and values must be strings, however, so to use
other objects as keys or to store other kinds of objects the user must
serialize them somehow, typically using marshal.dumps or pickle.dumps.

Starting with Python 2.3 the `bsddb' module requires the Berkeley DB
library version 3.1 or later (it is known to work with 3.1 thru 4.1 at
the time of this writing).

See also:
    <http://pybsddb.sourceforge.net/>
          Website with documentation for the new python Berkeley DB
          interface that closely mirrors the  sleepycat object oriented
          interface provided in Berkeley DB 3 and 4.

    <http://www.sleepycat.com/>
          Sleepycat Software produces the modern Berkeley DB library.

The following is a description of the legacy `bsddb' interface
compatible with the old python bsddb module.  For details about the more
modern Db and DbEnv object oriented interface see the above mentioned
pybsddb URL.

_Notice:_ [warning] This legacy interface is not thread safe in python
2.3.x or earlier.  Data corruption, core dumps or deadlocks may occur
if you attempt multi-threaded access.  You must use the modern pybsddb
interface linked to above if you need multi-threaded or multi-process
database access.

The `bsddb' module defines the following functions that create objects
that access the appropriate type of Berkeley DB file.  The first two
arguments of each function are the same.  For ease of portability, only
the first two arguments should be used in most instances.

`hashopen(filename[, flag[, mode[, bsize[, ffactor[, nelem[, cachesize[, hash[, lorder]]]]]]]])'
     Open the hash format file named FILENAME.  Files never intended to
     be preserved on disk may be created by passing `None' as the
     FILENAME.  The optional FLAG identifies the mode used to open the
     file.  It may be `r' (read only, default), `w' (read-write) , `c'
     (read-write - create if necessary) or `n' (read-write - truncate
     to zero length).  The other arguments are rarely used and are just
     passed to the low-level `dbopen()' function.  Consult the Berkeley
     DB documentation for their use and interpretation.

`btopen(filename[, flag[, mode[, btflags[, cachesize[, maxkeypage[, minkeypage[, psize[, lorder]]]]]]]])'
     Open the btree format file named FILENAME.  Files never intended
     to be preserved on disk may be created by passing `None' as the
     FILENAME.  The optional FLAG identifies the mode used to open the
     file.  It may be `r' (read only, default), `w' (read-write), `c'
     (read-write - create if necessary) or `n' (read-write - truncate
     to zero length).  The other arguments are rarely used and are just
     passed to the low-level dbopen function.  Consult the Berkeley DB
     documentation for their use and interpretation.

`rnopen(filename[, flag[, mode[, rnflags[, cachesize[, psize[, lorder[, reclen[, bval[, bfname]]]]]]]]])'
     Open a DB record format file named FILENAME.  Files never intended
     to be preserved on disk may be created by passing `None' as the
     FILENAME.  The optional FLAG identifies the mode used to open the
     file.  It may be `r' (read only, default), `w' (read-write), `c'
     (read-write - create if necessary) or `n' (read-write - truncate
     to zero length).  The other arguments are rarely used and are just
     passed to the low-level dbopen function.  Consult the Berkeley DB
     documentation for their use and interpretation.

See also:
     *Note dbhash:: DBM-style interface to the `bsddb'

_Notice:_ Beginning in 2.3 some Unix versions of Python may have a
`bsddb185' module.  This is present _only_ to allow backwards
compatibility with systems which ship with the old Berkeley DB 1.85
database library.  The `bsddb185' module should never be used directly
in new code.

* Menu:

* Hash::


File: python-lib.info,  Node: Hash,  Prev: bsddb,  Up: bsddb

Hash, BTree and Record Objects
------------------------------

Once instantiated, hash, btree and record objects support the same
methods as dictionaries.  In addition, they support the methods listed
below.  _Changed in Python version 2.3.1_

`close()'
     Close the underlying file.  The object can no longer be accessed.
     Since there is no open `open' method for these objects, to open
     the file again a new `bsddb' module open function must be called.

`keys()'
     Return the list of keys contained in the DB file.  The order of
     the list is unspecified and should not be relied on.  In
     particular, the order of the list returned is different for
     different file formats.

`has_key(key)'
     Return `1' if the DB file contains the argument as a key.

`set_location(key)'
     Set the cursor to the item indicated by KEY and return a tuple
     containing the key and its value.  For binary tree databases
     (opened using `btopen()'), if KEY does not actually exist in the
     database, the cursor will point to the next item in sorted order
     and return that key and value.  For other databases, `KeyError'
     will be raised if KEY is not found in the database.

`first()'
     Set the cursor to the first item in the DB file and return it.
     The order of keys in the file is unspecified, except in the case
     of B-Tree databases.

`next()'
     Set the cursor to the next item in the DB file and return it.  The
     order of keys in the file is unspecified, except in the case of
     B-Tree databases.

`previous()'
     Set the cursor to the previous item in the DB file and return it.
     The order of keys in the file is unspecified, except in the case
     of B-Tree databases.  This is not supported on hashtable databases
     (those opened with `hashopen()').

`last()'
     Set the cursor to the last item in the DB file and return it.  The
     order of keys in the file is unspecified.  This is not supported on
     hashtable databases (those opened with `hashopen()').

`sync()'
     Synchronize the database on disk.

Example:

     >>> import bsddb
     >>> db = bsddb.btopen('/tmp/spam.db', 'c')
     >>> for i in range(10): db['%d'%i] = '%d'% (i*i)
     ...
     >>> db['3']
     '9'
     >>> db.keys()
     ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
     >>> db.first()
     ('0', '0')
     >>> db.next()
     ('1', '1')
     >>> db.last()
     ('9', '81')
     >>> db.set_location('2')
     ('2', '4')
     >>> db.previous()
     ('1', '1')
     >>> for k, v in db.iteritems():
     ...     print k, v
     0 0
     1 1
     2 4
     3 9
     4 16
     5 25
     6 36
     7 49
     8 64
     9 81
     >>> 8 in db
     True
     >>> db.sync()
     0


File: python-lib.info,  Node: dumbdbm,  Next: zlib,  Prev: bsddb,  Up: Optional Operating System Services

Portable DBM implementation
===========================

Portable implementation of the simple DBM interface.

_Notice:_ The `dumbdbm' module is intended as a last resort fallback for
the `anydbm' module when no more robust module is available.  The
`dumbdbm' module is not written for speed and is not nearly as heavily
used as the other database modules.

The `dumbdbm' module provides a persistent dictionary-like interface
which is written entirely in Python.  Unlike other modules such as
`gdbm' and `bsddb', no external library is required.  As with other
persistent mappings, the keys and values must always be strings.

The module defines the following:

`error'
     Raised on dumbdbm-specific errors, such as I/O errors.  `KeyError'
     is raised for general mapping errors like specifying an incorrect
     key.

`open(filename[, flag[, mode]])'
     Open a dumbdbm database and return a dumbdbm object.  The FILENAME
     argument is the basename of the database file (without any specific
     extensions).  When a dumbdbm database is created, files with
     `.dat' and `.dir' extensions are created.

     The optional FLAG argument is currently ignored; the database is
     always opened for update, and will be created if it does not exist.

     The optional MODE argument is the UNIX mode of the file, used only
     when the database has to be created.  It defaults to octal `0666'
     (and will be modified by the prevailing umask).  _Changed in
     Python version 2.2_

See also:
     *Note anydbm:: Generic interface to `dbm'-style databases.  *Note
     dbm:: Similar interface to the DBM/NDBM library.  *Note gdbm::
     Similar interface to the GNU GDBM library.  *Note shelve::
     Persistence module which stores non-string data.  *Note whichdb::
     Utility module used to determine the type of an existing database.

* Menu:

* Dumbdbm Objects::


File: python-lib.info,  Node: Dumbdbm Objects,  Prev: dumbdbm,  Up: dumbdbm

Dumbdbm Objects
---------------

In addition to the methods provided by the `UserDict.DictMixin' class,
`dumbdbm' objects provide the following methods.

`sync()'
     Synchronize the on-disk directory and data files.  This method is
     called by the `sync' method of `Shelve' objects.


File: python-lib.info,  Node: zlib,  Next: gzip,  Prev: dumbdbm,  Up: Optional Operating System Services

Compression compatible with `gzip'
==================================

Low-level interface to compression and decompression routines
compatible with `gzip'.

For applications that require data compression, the functions in this
module allow compression and decompression, using the zlib library.
The zlib library has its own home page at <http://www.gzip.org/zlib/>.
Version 1.1.3 is the most recent version as of September 2000; use a
later version if one is available.  There are known incompatibilities
between the Python module and earlier versions of the zlib library.

The available exception and functions in this module are:

`error'
     Exception raised on compression and decompression errors.

`adler32(string[, value])'
     Computes a Adler-32 checksum of STRING.  (An Adler-32 checksum is
     almost as reliable as a CRC32 but can be computed much more
     quickly.)  If VALUE is present, it is used as the starting value
     of the checksum; otherwise, a fixed default value is used.  This
     allows computing a running checksum over the concatenation of
     several input strings.  The algorithm is not cryptographically
     strong, and should not be used for authentication or digital
     signatures.  Since the algorithm is designed for use as a checksum
     algorithm, it is not suitable for use as a general hash algorithm.

`compress(string[, level])'
     Compresses the data in STRING, returning a string contained
     compressed data.  LEVEL is an integer from `1' to `9' controlling
     the level of compression; `1' is fastest and produces the least
     compression, `9' is slowest and produces the most.  The default
     value is `6'.  Raises the `error' exception if any error occurs.

`compressobj([level])'
     Returns a compression object, to be used for compressing data
     streams that won't fit into memory at once.  LEVEL is an integer
     from `1' to `9' controlling the level of compression; `1' is
     fastest and produces the least compression, `9' is slowest and
     produces the most.  The default value is `6'.

`crc32(string[, value])'
     Computes a CRC (Cyclic Redundancy Check) checksum of STRING. If
     VALUE is present, it is used as the starting value of the
     checksum; otherwise, a fixed default value is used.  This allows
     computing a running checksum over the concatenation of several
     input strings.  The algorithm is not cryptographically strong, and
     should not be used for authentication or digital signatures.  Since
     the algorithm is designed for use as a checksum algorithm, it is
     not suitable for use as a general hash algorithm.

`decompress(string[, wbits[, bufsize]])'
     Decompresses the data in STRING, returning a string containing the
     uncompressed data.  The WBITS parameter controls the size of the
     window buffer.  If BUFSIZE is given, it is used as the initial
     size of the output buffer.  Raises the `error' exception if any
     error occurs.

     The absolute value of WBITS is the base two logarithm of the size
     of the history buffer (the "window size") used when compressing
     data.  Its absolute value should be between 8 and 15 for the most
     recent versions of the zlib library, larger values resulting in
     better compression at the expense of greater memory usage.  The
     default value is 15.  When WBITS is negative, the standard `gzip'
     header is suppressed; this is an undocumented feature of the zlib
     library, used for compatibility with `unzip''s compression file
     format.

     BUFSIZE is the initial size of the buffer used to hold
     decompressed data.  If more space is required, the buffer size
     will be increased as needed, so you don't have to get this value
     exactly right; tuning it will only save a few calls to `malloc()'.
     The default size is 16384.

`decompressobj([wbits])'
     Returns a decompression object, to be used for decompressing data
     streams that won't fit into memory at once.  The WBITS parameter
     controls the size of the window buffer.

Compression objects support the following methods:

`compress(string)'
     Compress STRING, returning a string containing compressed data for
     at least part of the data in STRING.  This data should be
     concatenated to the output produced by any preceding calls to the
     `compress()' method.  Some input may be kept in internal buffers
     for later processing.

`flush([mode])'
     All pending input is processed, and a string containing the
     remaining compressed output is returned.  MODE can be selected
     from the constants `Z_SYNC_FLUSH',  `Z_FULL_FLUSH',  or
     `Z_FINISH', defaulting to `Z_FINISH'.  `Z_SYNC_FLUSH' and
     `Z_FULL_FLUSH' allow compressing further strings of data and are
     used to allow partial error recovery on decompression, while
     `Z_FINISH' finishes the compressed stream and prevents compressing
     any more data.  After calling `flush()' with MODE set to
     `Z_FINISH', the `compress()' method cannot be called again; the
     only realistic action is to delete the object.

Decompression objects support the following methods, and two attributes:

`unused_data'
     A string which contains any bytes past the end of the compressed
     data.  That is, this remains `""' until the last byte that contains
     compression data is available.  If the whole string turned out to
     contain compressed data, this is `""', the empty string.

     The only way to determine where a string of compressed data ends
     is by actually decompressing it.  This means that when compressed
     data is contained part of a larger file, you can only find the end
     of it by reading data and feeding it followed by some non-empty
     string into a decompression object's `decompress' method until the
     `unused_data' attribute is no longer the empty string.

`unconsumed_tail'
     A string that contains any data that was not consumed by the last
     `decompress' call because it exceeded the limit for the
     uncompressed data buffer.  This data has not yet been seen by the
     zlib machinery, so you must feed it (possibly with further data
     concatenated to it) back to a subsequent `decompress' method call
     in order to get correct output.

`decompress(string)'
     {[max_length]} Decompress STRING, returning a string containing the
     uncompressed data corresponding to at least part of the data in
     STRING.  This data should be concatenated to the output produced
     by any preceding calls to the `decompress()' method.  Some of the
     input data may be preserved in internal buffers for later
     processing.

     If the optional parameter MAX_LENGTH is supplied then the return
     value will be no longer than MAX_LENGTH. This may mean that not
     all of the compressed input can be processed; and unconsumed data
     will be stored in the attribute `unconsumed_tail'. This string
     must be passed to a subsequent call to `decompress()' if
     decompression is to continue.  If MAX_LENGTH is not supplied then
     the whole input is decompressed, and `unconsumed_tail' is an empty
     string.

`flush()'
     All pending input is processed, and a string containing the
     remaining uncompressed output is returned.  After calling
     `flush()', the `decompress()' method cannot be called again; the
     only realistic action is to delete the object.

See also:
     *Note gzip:: Reading and writing `gzip'-format files.

    <http://www.gzip.org/zlib/>
          The zlib library home page.


File: python-lib.info,  Node: gzip,  Next: bz2,  Prev: zlib,  Up: Optional Operating System Services

Support for `gzip' files
========================

Interfaces for `gzip' compression and decompression using file objects.

The data compression provided by the `zlib' module is compatible with
that used by the GNU compression program `gzip'.  Accordingly, the
`gzip' module provides the `GzipFile' class to read and write
`gzip'-format files, automatically compressing or decompressing the
data so it looks like an ordinary file object.  Note that additional
file formats which can be decompressed by the `gzip' and `gunzip'
programs, such as those produced by `compress' and `pack', are not
supported by this module.

The module defines the following items:

`GzipFile([filename[, mode[, compresslevel[, fileobj]]]])'
     Constructor for the `GzipFile' class, which simulates most of the
     methods of a file object, with the exception of the `readinto()'
     and `truncate()' methods.  At least one of FILEOBJ and FILENAME
     must be given a non-trivial value.

     The new class instance is based on FILEOBJ, which can be a regular
     file, a `StringIO' object, or any other object which simulates a
     file.  It defaults to `None', in which case FILENAME is opened to
     provide a file object.

     When FILEOBJ is not `None', the FILENAME argument is only used to
     be included in the `gzip' file header, which may includes the
     original filename of the uncompressed file.  It defaults to the
     filename of FILEOBJ, if discernible; otherwise, it defaults to the
     empty string, and in this case the original filename is not
     included in the header.

     The MODE argument can be any of `'r'', `'rb'', `'a'', `'ab'',
     `'w'', or `'wb'', depending on whether the file will be read or
     written.  The default is the mode of FILEOBJ if discernible;
     otherwise, the default is `'rb''.  If not given, the 'b' flag will
     be added to the mode to ensure the file is opened in binary mode
     for cross-platform portability.

     The COMPRESSLEVEL argument is an integer from `1' to `9'
     controlling the level of compression; `1' is fastest and produces
     the least compression, and `9' is slowest and produces the most
     compression.  The default is `9'.

     Calling a `GzipFile' object's `close()' method does not close
     FILEOBJ, since you might wish to append more material after the
     compressed data.  This also allows you to pass a `StringIO' object
     opened for writing as FILEOBJ, and retrieve the resulting memory
     buffer using the `StringIO' object's `getvalue()' method.

`open(filename[, mode[, compresslevel]])'
     This is a shorthand for `GzipFile(FILENAME,' `MODE,'
     `COMPRESSLEVEL)'.  The FILENAME argument is required; MODE
     defaults to `'rb'' and COMPRESSLEVEL defaults to `9'.

See also:
     *Note zlib:: The basic data compression module needed to support
     the `gzip' file format.


File: python-lib.info,  Node: bz2,  Next: zipfile,  Prev: gzip,  Up: Optional Operating System Services

Compression compatible with `bzip2'
===================================

Interface to compression and decompression routines compatible with
`bzip2'.

_Added in Python version 2.3_

This module provides a comprehensive interface for the bz2 compression
library.  It implements a complete file interface, one-shot
(de)compression functions, and types for sequential (de)compression.

Here is a resume of the features offered by the bz2 module:

   * `BZ2File' class implements a complete file interface, including
     `readline()', `readlines()', `writelines()', `seek()', etc;

   * `BZ2File' class implements emulated `seek()' support;

   * `BZ2File' class implements universal newline support;

   * `BZ2File' class offers an optimized line iteration using the
     readahead algorithm borrowed from file objects;

   * Sequential (de)compression supported by `BZ2Compressor' and
     `BZ2Decompressor' classes;

   * One-shot (de)compression supported by `compress()' and
     `decompress()' functions;

   * Thread safety uses individual locking mechanism;

   * Complete inline documentation;

* Menu:

* Decompression of files::
* Sequential decompression::
* One-shot decompression::


File: python-lib.info,  Node: Decompression of files,  Next: Sequential decompression,  Prev: bz2,  Up: bz2

(De)compression of files
------------------------

Handling of compressed files is offered by the `BZ2File' class.

`BZ2File(filename[, mode[, buffering[, compresslevel]]])'
     Open a bz2 file. Mode can be either `'r'' or `'w'', for reading
     (default) or writing. When opened for writing, the file will be
     created if it doesn't exist, and truncated otherwise. If BUFFERING
     is given, `0' means unbuffered, and larger numbers specify the
     buffer size; the default is `0'. If COMPRESSLEVEL is given, it
     must be a number between `1' and `9'; the default is `9'.  Add a
     `U' to mode to open the file for input with universal newline
     support. Any line ending in the input file will be seen as a `\n'
     in Python.  Also, a file so opened gains the attribute `newlines';
     the value for this attribute is one of `None' (no newline read
     yet), `'\r'', `'\n'', `'\r\n'' or a tuple containing all the
     newline types seen. Universal newlines are available only when
     reading.  Instances support iteration in the same way as normal
     `file' instances.

`close()'
     Close the file. Sets data attribute `closed' to true. A closed file
     cannot be used for further I/O operations. `close()' may be called
     more than once without error.

`read([size])'
     Read at most SIZE uncompressed bytes, returned as a string. If the
     SIZE argument is negative or omitted, read until EOF is reached.

`readline([size])'
     Return the next line from the file, as a string, retaining newline.
     A non-negative SIZE argument limits the maximum number of bytes to
     return (an incomplete line may be returned then). Return an empty
     string at EOF.

`readlines([size])'
     Return a list of lines read. The optional SIZE argument, if given,
     is an approximate bound on the total number of bytes in the lines
     returned.

`xreadlines()'
     For backward compatibility. `BZ2File' objects now include the
     performance optimizations previously implemented in the
     `xreadlines' module.  _This is deprecated in Python 2.3.  This
     exists only for compatibility with the method by this name on
     `file' objects, which is deprecated.  Use `for line in file'
     instead._

`seek(offset[, whence])'
     Move to new file position. Argument OFFSET is a byte count.
     Optional argument WHENCE defaults to `0' (offset from start of
     file, offset should be `>= 0'); other values are `1' (move
     relative to current position, positive or negative), and `2' (move
     relative to end of file, usually negative, although many platforms
     allow seeking beyond the end of a file).

     Note that seeking of bz2 files is emulated, and depending on the
     parameters the operation may be extremely slow.

`tell()'
     Return the current file position, an integer (may be a long
     integer).

`write(data)'
     Write string DATA to file. Note that due to buffering, `close()'
     may be needed before the file on disk reflects the data written.

`writelines(sequence_of_strings)'
     Write the sequence of strings to the file. Note that newlines are
     not added.  The sequence can be any iterable object producing
     strings. This is equivalent to calling write() for each string.


File: python-lib.info,  Node: Sequential decompression,  Next: One-shot decompression,  Prev: Decompression of files,  Up: bz2

Sequential (de)compression
--------------------------

Sequential compression and decompression is done using the classes
`BZ2Compressor' and `BZ2Decompressor'.

`BZ2Compressor([compresslevel])'
     Create a new compressor object. This object may be used to compress
     data sequentially. If you want to compress data in one shot, use
     the `compress()' function instead. The COMPRESSLEVEL parameter, if
     given, must be a number between `1' and `9'; the default is `9'.

`compress(data)'
     Provide more data to the compressor object. It will return chunks
     of compressed data whenever possible. When you've finished
     providing data to compress, call the `flush()' method to finish
     the compression process, and return what is left in internal
     buffers.

`flush()'
     Finish the compression process and return what is left in internal
     buffers. You must not use the compressor object after calling this
     method.

`BZ2Decompressor()'
     Create a new decompressor object. This object may be used to
     decompress data sequentially. If you want to decompress data in
     one shot, use the `decompress()' function instead.

`decompress(data)'
     Provide more data to the decompressor object. It will return
     chunks of decompressed data whenever possible. If you try to
     decompress data after the end of stream is found, `EOFError' will
     be raised. If any data was found after the end of stream, it'll be
     ignored and saved in `unused_data' attribute.


File: python-lib.info,  Node: One-shot decompression,  Prev: Sequential decompression,  Up: bz2

One-shot (de)compression
------------------------

One-shot compression and decompression is provided through the
`compress()' and `decompress()' functions.

`compress(data[, compresslevel])'
     Compress DATA in one shot. If you want to compress data
     sequentially, use an instance of `BZ2Compressor' instead. The
     COMPRESSLEVEL parameter, if given, must be a number between `1'
     and `9'; the default is `9'.

`decompress(data)'
     Decompress DATA in one shot. If you want to decompress data
     sequentially, use an instance of `BZ2Decompressor' instead.


File: python-lib.info,  Node: zipfile,  Next: tarfile,  Prev: bz2,  Up: Optional Operating System Services

Work with ZIP archives
======================

Read and write ZIP-format archive files.

_Added in Python version 1.6_

The ZIP file format is a common archive and compression standard.  This
module provides tools to create, read, write, append, and list a ZIP
file.  Any advanced use of this module will require an understanding of
the format, as defined in .

This module does not currently handle ZIP files which have appended
comments, or multi-disk ZIP files.

The available attributes of this module are:

`error'
     The error raised for bad ZIP files.

`ZipFile'
     The class for reading and writing ZIP files.  See "" (section
     *Note ZipFile Objects::) for constructor details.

`PyZipFile'
     Class for creating ZIP archives containing Python libraries.

`ZipInfo([filename[, date_time]])'
     Class used the represent infomation about a member of an archive.
     Instances of this class are returned by the `getinfo()' and
     `infolist()' methods of `ZipFile' objects.  Most users of the
     `zipfile' module will not need to create these, but only use those
     created by this module.  FILENAME should be the full name of the
     archive member, and DATE_TIME should be a tuple containing six
     fields which describe the time of the last modification to the
     file; the fields are described in section *Note tarfile::,
     "ZipInfo Objects."

`is_zipfile(filename)'
     Returns `True' if FILENAME is a valid ZIP file based on its magic
     number, otherwise returns `False'.  This module does not currently
     handle ZIP files which have appended comments.

`ZIP_STORED'
     The numeric constant for an uncompressed archive member.

`ZIP_DEFLATED'
     The numeric constant for the usual ZIP compression method.  This
     requires the zlib module.  No other compression methods are
     currently supported.

See also:
     `PKZIP Application Note'{Documentation on the ZIP file format by
     Phil Katz, the creator of the format and algorithms used.}

     `Info-ZIP Home Page'{ Information about the Info-ZIP project's ZIP
     archive programs and development libraries.}

* Menu:

* ZipFile Objects::
* PyZipFile Objects::
* ZipInfo Objects::


File: python-lib.info,  Node: ZipFile Objects,  Next: PyZipFile Objects,  Prev: zipfile,  Up: zipfile

ZipFile Objects
---------------

`ZipFile(file[, mode[, compression]])'
     Open a ZIP file, where FILE can be either a path to a file (a
     string) or a file-like object.  The MODE parameter should be `'r''
     to read an existing file, `'w'' to truncate and write a new file,
     or `'a'' to append to an existing file.  For MODE is `'a'' and FILE
     refers to an existing ZIP file, then additional files are added to
     it.  If FILE does not refer to a ZIP file, then a new ZIP archive
     is appended to the file.  This is meant for adding a ZIP archive
     to another file, such as `python.exe'.  Using

          cat myzip.zip >> python.exe

     also works, and at least `WinZip' can read such files.
     COMPRESSION is the ZIP compression method to use when writing the
     archive, and should be `ZIP_STORED' or `ZIP_DEFLATED';
     unrecognized values will cause `RuntimeError' to be raised.  If
     `ZIP_DEFLATED' is specified but the `zlib' module is not available,
     `RuntimeError' is also raised.  The default is `ZIP_STORED'.

`close()'
     Close the archive file.  You must call `close()' before exiting
     your program or essential records will not be written.

`getinfo(name)'
     Return a `ZipInfo' object with information about the archive
     member NAME.

`infolist()'
     Return a list containing a `ZipInfo' object for each member of the
     archive.  The objects are in the same order as their entries in
     the actual ZIP file on disk if an existing archive was opened.

`namelist()'
     Return a list of archive members by name.

`printdir()'
     Print a table of contents for the archive to `sys.stdout'.

`read(name)'
     Return the bytes of the file in the archive.  The archive must be
     open for read or append.

`testzip()'
     Read all the files in the archive and check their CRC's.  Return
     the name of the first bad file, or else return `None'.

`write(filename[, arcname[, compress_type]])'
     Write the file named FILENAME to the archive, giving it the
     archive name ARCNAME (by default, this will be the same as
     FILENAME).  If given, COMPRESS_TYPE overrides the value given for
     the COMPRESSION parameter to the constructor for the new entry.
     The archive must be open with mode `'w'' or `'a''.

`writestr(zinfo_or_arcname, bytes)'
     Write the string BYTES to the archive; ZINFO_OR_ARCNAME is either
     the file name it will be given in the archive, or a `ZipInfo'
     instance.  If it's an instance, at least the filename, date, and
     time must be given.  If it's a name, the date and time is set to
     the current date and time. The archive must be opened with mode
     `'w'' or `'a''.

The following data attribute is also available:

`debug'
     The level of debug output to use.  This may be set from `0' (the
     default, no output) to `3' (the most output).  Debugging
     information is written to `sys.stdout'.

